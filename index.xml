<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2cloudlab | 企业数字化转型的催化剂</title>
    <link>https://2cloudlab.com/</link>
    <description>Recent content on 2cloudlab | 企业数字化转型的催化剂</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Apr 2020 12:27:38 +0600</lastBuildDate>
    
	<atom:link href="https://2cloudlab.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>DynamoDB的学习指南</title>
      <link>https://2cloudlab.com/nosql/nosql-index/</link>
      <pubDate>Wed, 15 Apr 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/nosql-index/</guid>
      <description>如果你在软件行业（尤其是后端服务的研发）里从业几年，你肯定会听说过与存储和处理数据相关的几个时髦的技术词：NoSQL，大数据，云计算，ServerLess，ACID，CAP，分布式等等。驱动这些技术发展的原因是多样的，主要有以下几点：
 互联网巨头（比如Google，Microsoft，Amazon，Facebook，LinkedIn，Netflix以及Twitter）需要面对体量庞大的数据和流量，这迫使它们创造新的工具来高效处理海量数据 需要更短的研发周期和更灵活的数据模型支撑更加敏捷，更加容易测试和及时响应市场的业务场景 开源软件的发展变得更加成熟，而且与商业软件相比，提供了更好的功能 CPU的时钟频率很难提高，多核CPU已经逐渐成为标准，网络变得更快了（从原来的2G转变成为4G，到现在的5G）。这意味着并行计算的能力将会增强 得益于云计算服务的出现，即使你在一个小团队，也能打造一个分布式系统，甚至在不同的地理位置的不同机器上运行这套系统 许多数字化服务会一直处于7*24小时可用的状态，短暂的停机是无法接受的（比如Amazon短暂地停机会导致其商品买卖交易活动停滞，并引起经济损失）  因此，过去10年，为了应对大规模数据所带来的挑战，相应的工具和技术相继被提出。其中新型数据库系统（&amp;quot;NoSQL&amp;quot;）受到了很多关注，但是消息队列（message queues），缓存（caches），搜索引擎，数据流处理框架（Kafka和Samza）和其它分布式技术也相当重要！一个成熟的分布式系统一般会同时应用这些技术和工具。
以上提到的技术和工具都有对应的书籍介绍，而这个系列的文章（其列表如下）将聚焦在NoSQL数据库上，特别是AWS提供的DynamoDB。对于想要从事数据服务研发的工程师们，掌握NoSQL技能是必备的，因为它能够存储大规模数据（超过100TBs）的同时提供稳定的性能（数据操作的时间低于1ms），而要想在SQL数据库中拥有同样的能力，则需要付出巨大的代价，有时甚至无法实现！
NoSQL类型的数据库有很多，包括MongoDB，CouchDB和DynamoDB等。之所以使用DynamoDB的原因之一是它完全托管于AWS，开发者无需准备运行它的机器就能直接创建表。除此之外，DynamoDB还提供了永久的免费套餐。你想成为操作大规模数据的大师吗？如果答案是：Yes，那么你可以使用DynamoDB，并根据以下文章来实现这个目标！
介绍  1.1 什么是DynamoDB？ 1.2 DynamoDB的关键概念 1.3 关于Dynamo的论文 1.4 DynamoDB的环境搭建  单项数据操作  2.1 DynamoDB中，每项数据（item）的构成单元 2.2 在DynamoDB中插入和读取数据项 2.3 基础表达式 2.4 更新和删除数据项  多项数据操作  3.1 同时处理多项数据 3.2 查询 3.3 遍历 3.4 过滤  高级功能  4.1 附加索引 4.2 本地附加索引 4.3 全局附加索引 4.4 DynamoDB流  运维相关  5.1 Provisioning tables 5.2 安全 5.3 备份和恢复 5.4 自动伸缩 5.5 Global Tables  数据建模案例  6.</description>
    </item>
    
    <item>
      <title>如何规模化企业的数字化服务--Kubernetes的最佳实践</title>
      <link>https://2cloudlab.com/blog/how-to-improve-organization-effect-kubernetes/</link>
      <pubDate>Fri, 20 Mar 2020 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-improve-organization-effect-kubernetes/</guid>
      <description>企业的线上产品的发展主要分为3个阶段。第一阶段主要是快速打造产品，然后推向市场并验证想法；第二阶段主要是打磨产品同时发展用户基数，使得用户基数达到千万级别；第三阶段则是维护产品，迭代新功能，保证产品能够为企业带来持续的收入。每一个阶段都会有对应的技术手段来支撑，本文的内容主要解决企业在第二阶段所面临的挑战。这些挑战主要有：企业如何在原来的基础上重构数字化产品？企业如何构建支撑千万级用户的数字化产品？对于后者，企业需要综合多种技术手段来实现，其中Kubernetes（K8S）在容器编排方面为拥有千万级别用户群体的服务提供了支持。接下来，让我们看看K8S是如何规模化数字化产品的。
 Kubernetes所解决的问题 什么是Kubernetes(K8S) 为什么选择K8S K8S的组成部分 K8S的资源类型 在AWS上搭建K8S服务的选项  Kubernetes所解决的问题 当一款数字化产品的用户基数非常庞大的时候（比如每天的访问量达到几千万人次时），企业需要升级其技术解决方案，以便能够支撑庞大的用户群体。拥有庞大用户群体的数字化服务有很多，比如Google的搜索引擎，淘宝，微博等等。而这类数字化服务有一个共同的特征：其后台运行着成成千上万台服务器，由它们向用户提供服务。通过人工来管理这群服务器显然不是一个可行的办法，因此Google的工程师为了高效管理这种量级的服务器，发明了这个工具：Kubernetes（K8S）。通过这个工具，工程师只需要键入几条命令就可以同时操作多台机器，从而实现轻松管理成千上万台服务器。
这些数字化产品大多都是微服务化的，而微服务的几大特点就是：服务与服务之间是相互独立的；它们之间是通过行为来交互的；为了高可用性，每一个服务都会被复制到不同的服务器上，当某台服务器坏了或者死机了，那么运行在其它服务器上的服务依然能够提供服务；不同服务互相协作，最终支撑了数字化产品。K8S特别适合微服务场景，比如工程师只需要执行一个命令就能让K8S部署某类服务，并自动替换失败的服务。除此之外，工程师还可以通过一个命令使得K8S自动部署或更新服务，这些服务能够根据负载的多少而自动增加或减少。为了方便K8S部署，其部署单元被抽象出来，而这种单元就是我们常常见到的容器，其中Docker是一款非常流行的容器工具，因此K8S和Docker工具结合很好地支持微服务结构的数字化产品。
使用K8S能够方便地为数字化产品的负载能力提供横向扩展，那么K8S是如何做到的？接下来我们要了解什么是K8S？它提供了哪些功能？
什么是Kubernetes(K8S) Kubernetes (K8S)是一套管理容器资源的开源系统，它提供了以下功能:
 分配资源  它会根据资源的使用情况(这些资源包括数据中心，服务器，CPU，内存，端口等)，在一族服务器上，以最优的方式，创建和运行容器。
 部署  它支持多种在线逐步更新策略，这些策略有rolling deployment， blue-green deployment以及 canary deployment。如果在更新过程中产生错误，它会自动恢复到上一次可用的状态，从而确保服务7*24小时可用。
 自带修复功能  它会一直监控资源的运行状态，自动将可用的资源替换不可使用的资源。
 弹性伸缩  它支持横向和纵向伸缩。负载增多或减少时，它可以自动增加或减少适度的资源来响应负载。它也可以升级或降级资源的处理能力来支持纵向扩展，比如提高CPU的处理能力或者增加内存。
 负载均衡  它能使外部访问内部资源(常见的资源有container)，并将外部请求均匀地分配给不同的资源。
 发现服务  它有内置的DNS服务，并提供Service资源，使得容器能够找到彼此来进行通信。
 配置和授权  它允许你设置不同的环境变量来区分不同的环境，这些环境有stage、test和prod。也允许你为资源设置不同的访问权限。
为什么选择K8S K8S作为容器化应用的编排系统，已经广泛应用于大多数企业。它之所以流行的原因有以下几点：
 丰富的功能  它为管理容器提供了大量功能，这些功能包括弹性伸缩，自动修复，在线部署，服务发现，秘钥管理，配置管理，bin packing, storage orchestration, batch execution, access controls, log aggregation, SSH access, batch processing, and much more.</description>
    </item>
    
    <item>
      <title>从提出想法-&gt;对外发布产品--如何0成本在github上缩短该过程</title>
      <link>https://2cloudlab.com/blog/how-to-craft-url-shorten-service-for-one-day/</link>
      <pubDate>Thu, 19 Mar 2020 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-craft-url-shorten-service-for-one-day/</guid>
      <description>Craft a shorten URL service base on AWS in 1 day With Cloud Computing becoming popular, uniform and standard software development methodologies are arising, meaning that companies can leverage out-of-the-box infrastructures provided by Cloud providers, such as AWS, to craft complex yet competitive software product in order to domain markets in a short time, sometime, even in a day. Here, I will show you how to combine some sort of services provided by AWS, to build a production-grade shorten URL service with high availability, resiliency and maintainability in just one day!</description>
    </item>
    
    <item>
      <title>如何提高企业的研发效率--CI/CD</title>
      <link>https://2cloudlab.com/blog/why-organization-should-practice-cicd/</link>
      <pubDate>Wed, 18 Mar 2020 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/why-organization-should-practice-cicd/</guid>
      <description>CI/CD是现代软件研发过程中必不可少的基础设施。类似于福特流水线，它能够帮助企业提高软件的研发效率，提高软件的质量以及对外发布新功能。CI/CD能够帮助企业的研发团队提高研发效率。CI/CD将企业中的所有研发人员，包括研发团队，测试团队，DevOps团队，串联在一起，使得上一个团队的输出都可以顺利地流转到下一个团队。CI/CD能够帮助企业提高软件质量。研发团队借助CI/CD能够快速看到修改产品之后的结果，从而能够及时解决因修改不当而引起的问题；测试团队将UI测试，集成测试接入到CI/CD中，使得软件产品对外发布之前，都有足够的自动化测试来验证其功能。CI/CD能够帮助企业及时对外发布产品的新功能。DevOps团队只需要执行一个命令，就能将研发团队所研发的新功能通过机器自动地部署到生产环境中，有时还能支持线上实时更新！CI/CD分为2部分，它们分别是CI和CD。每个部分都需要借助一些工具和经验来实现，其中&amp;lt;如何0成本在github上构建CI&amp;gt;通过一个例子来构建CI，而本文将围绕CD来展开，包括Continue Test，Continue Monitor，Continue Security，Continue Deployment等。
2cloudlab.com为企业准备产品的运行环境，只需要1天！</description>
    </item>
    
    <item>
      <title>如何0成本在github上构建CI</title>
      <link>https://2cloudlab.com/blog/how-to-setup-ci-service-base-on-github/</link>
      <pubDate>Tue, 17 Mar 2020 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-setup-ci-service-base-on-github/</guid>
      <description>现代软件的研发流程基本上均会配备一定程度的CI/CD（这篇文章解释了为何需要在企业里实施CI/CD），整个流程主要分为CI和CD部分，这篇文章将围绕CI部分展开，并通过一个具体的例子解释如何0成本在github上构建CI。构建CI的最佳实践离不开Trunk Based Development的分支策略，感兴趣的读者可以通过这篇文章来了解什么是Trunk Based Development。在github上构建CI有2个好处：无需任何费用和有大量可以用于构建CI的模块，借助这2个好处，小规模团队可以快速地搭建还不错的CI流程。接下来，让我们结合一个使用Go编写的Hello World例子以及基于Trunk-Based Development模式来构建这个CI流程。
这篇文章将分为以下几个部分来讲解：
 在github上构建CI的基本思路 在github上构建CI的优势 通过一个Go示例在github上构建CI 总结  在github上构建CI的基本思路 构建CI有2种方式，一种是组建团队从0开始，另外一种是借助第三方服务开始。在github上构建CI属于后者，其优势在于github提供了许多方便开发者研发的服务，其中有3种服务可用于免费构建CI，它们分别是：免费托管源码，免费存储以及免费构建服务（也就是最近推出的Actions服务）。有了这3种服务，任何一个团队均可以根据自身的情况来构建CI。接下来，我将基于Trunk-Based Development模式提出实践CI的一种方法，这种方法提出了2个独立的流程，并定义了触发这2个流程的条件。
首先，我们需要定义一个流程（master_workflow），这个流程的作用是快速响应master分支上的每一次改动。该分支上每一次改动都会自动启动服务器或虚拟机来执行该流程，并将结果反馈（比如通过邮件通知的方式）给研发团队。这个流程的主要作用在于每天都确保master分支是健康的，比如语法规则是正确的，编译是成功的和单元测试能通过，因此该流程的一大特点是执行周期通常限制在10~30分钟内。这一要求使得构成该流程的步骤尽可能的少，下面是构成该流程的几个步骤：
 准备编译环境 安装依赖库 获取源代码 检测代码的合法性 编译源代码 执行自动化测试（仅仅包括单元测试） 生成测试报告  为了缩短这个流程的执行周期，可以考虑这些方法：将准备编译环境和安装依赖库步骤提前合并成一个步骤（通过Docker技术），无需在运行时准备；将检测代码的合法性和编译源代码步骤分布在不同的机器上同时执行；在执行自动化测试的步骤中并发执行单元测试。缩短这个流程的执行周期是为了让整个团队更快地看到每一次修改的结果，如果这个修改阻碍了团队的工作（比如编译失败了），那么提交该修改的研发工作者能够第一时间修复。
其次，我们还需要定义一个集成流程（integration_workflow），这个流程的作用是将所有组件集成在一个完整的压缩包里，并发布到一个共有的存储空间，以便测试团队和DevOps团队展开后续的测试和部署工作。这个流程不仅包括之前流程所定义的步骤，而且还新增了集成和归档步骤，如下所示：
 准备编译环境 安装依赖库 获取源代码 检测代码的合法性 编译源代码 执行自动化测试（包括单元测试和集成测试） 生成测试报告 集成和归档  **注：**此时，执行自动化测试包括了集成测试。因此，从总体而言，这个流程的运行周期会更长一点，通常在30~60分钟。
以上就是基于Trunk-Based Development模式，在github上构建CI的基本思路。首先，我们需要为master分支定义一个流程，该分支上的每次修改都会触发该流程；其次，我们需要为release分支定义另外一个流程，该分支上的每一次修改都会触发该流程，并将集成包发布到一个共有存储空间。为何需要定义这2个流程，读者可以参考这篇文章。
在github上构建CI的优势 你可以选择组建一支团队来打造CI/CD，这种方式需要自己搭建服务器，安装软件（比如Jenkins）和配置，因此所需时间会较长。另外，你也可以选择第三方服务来搭建CI/CD（比如在github上构建CI）。在github上搭建CI有2个好处，它们分别是免费和共享其他人的成果。
github向开发者提供了3种免费的服务来搭建CI，它们分别是源码托管，归档存储和Actions服务。开发者可以免费地将代码发布到github上，世界各地的开发者可以参与进来共同开发；开发者也可以免费地使用github所提供的Actions服务来构建流程；开发者可以将流程输出的集成包发布到github提供的存储服务里，供用户使用。
这3种服务不仅免费，而且其中Actions服务提供了可复用的模块。这些可复用的模块是由全世界的开发者贡献的，因此可以直接将这些模块组合在一起构成适合自己的CI流程。比如这篇文章的示例使用了Go相关的Actions模块来构建上一节提到的2个流程。
github平台存储了开发者的代码，提供了搭建CI的Action服务，拥有大量可复用的模块以及支持存储，此时，开发者只需要使用这些可复用的模块来定义流程，便可以将代码，Actions服务和存储服务联系在一起。而流程的定义是通过yaml文件来完成的，比如上一节的2个流程就分别对应着文件master_workflow.yaml和integration_workflow.yaml。
组建一个团队来搭建CI，需要准备服务器，安装软件，用网线连接服务器等，而借助github，则只需要编写yaml文件就能快速构建出一个稳定的CI，这种转变大大地缩短了搭建CI的时间，让开发者专注于软件的功能研发！
接下来让我们看一个具体的例子来实践在github上构建CI
通过一个Go示例在github上构建CI 这个例子是由Go语言来编写的，完整的源码可以到这里获取，其目录结构如下所示：
. |____.github | |____workflows | | |____integration_workflow.yaml | | |____master_workflow.yaml |____go.mod |____main.go |____main_integration_test.go |____main_test.go |____Makefile |____mylib | |____external_lib.go | |____external_lib_test.</description>
    </item>
    
    <item>
      <title>如何提高企业的研发效率--trunk-based development</title>
      <link>https://2cloudlab.com/blog/why-organization-should-use-trunk-based-development/</link>
      <pubDate>Mon, 16 Mar 2020 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/why-organization-should-use-trunk-based-development/</guid>
      <description>企业的研发团队在研发产品功能时通常会选择2种分支管理策略，它们分别是Feature Branches Development和Trunk-based Development。2种分支管理策略都有它们适用的场景，比如在github上研发开源软件时，经常会使用Feature Branches Development模式，而Google，Facebook，LinkedIn，微软常常会使用Trunk-based Development模式。企业在实施CI（持续集成）时通常需要Trunk-based Development方面的实践，原因在于这种模式能够快速输出集成的结果。本文将围绕Trunk-based Development展开，并提供一些可实施该模式的操作步骤。
 什么是Trunk-based Development？ 团队需要掌握哪些技巧来实践Trunk-based Development？ 为Trunk-Based Development配套CI服务 Trunk-Based Development的实施细节 使用github来实施Trunk-Based Development的基本思路 结论和参考  什么是Trunk-based Development？ Trunk-based Development是指：所有研发人员围绕主分支trunk(也就是github上的master分支)来共同研发，在研发过程中拒绝创建存活时间较长的分支，并使用Feature Toggles和Branch by Abstraction等技术在主分支上逐步发布需要长时间（通常是1周）才能研发完成的功能。官方对Trunk-based Development的概括如下所示：
 A source-control branching model, where developers collaborate on code in a single branch called ‘trunk’ *, resist any pressure to create other long-lived development branches by employing documented techniques. They therefore avoid merge hell, do not break the build, and live happily ever after.</description>
    </item>
    
    <item>
      <title>如何正确使用DynamoDB</title>
      <link>https://2cloudlab.com/nosql/how-to-use-dynamodb-effectively/</link>
      <pubDate>Sun, 15 Mar 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/how-to-use-dynamodb-effectively/</guid>
      <description>把DynamoDB作为数据层的引擎能带来许多好处，一方面，它能够存储大规模数据的同时也保持高性能的数据存取，另外一方面，它能减少运维工作。打造一个稳定高效的数据服务需要解决很多问题，这些问题有：选择哪些工具为DynamoDB建模？如何记录热数据以及引发异常的数据？如何保证数据是加密存储在磁盘的？如何减少存取数据的响应延时？限制哪些用户拥有哪些数据存取的权限？选择哪种类型的数据备份策略？如何将数据发布到全球并保持同步？DynamoDB的最佳设计原则有哪些？等等。
 使用频率很高的数据被称为热数据。比如DynamoDB中的某项数据item每秒被访问1亿次，那么这个item就是一项热数据。
 以上问题有的一开始就会遇到（比如选择数据建模工具），有的则只在业务发展到一定阶段才会遇到（比如将企业的业务从中国区扩展到北美区）。不同问题需要不同的工具或者服务来解决，使用DynamoDB服务的一个好处是：它集成了很多开箱即用的服务。作为开发者，只需要创建这些服务，然后将其串联在一起形成一个完整的数据服务，而无需从头开始搭建解决问题的方案。
1.1 使用DynamoDB时需要考虑的问题 围绕DynamoDB展开研发数据服务需要在不同阶段考虑不同问题。这些问题将在研发所处的阶段一一暴露出来，而企业发展到一定阶段时才需要考虑属于这个阶段的问题。这3个阶段分别是：研发初期，测试阶段和发布阶段。其中发布阶段需要考虑的问题有很多。
在研发初期，需要为团队选择可视化工具来提供数据建模，可视化数据，以及操作数据。除此之外，还需要在本地安装DynamoDB，以便研发人员能够快速地在本地验证其想法。
在测试阶段，则需要搭建线上的测试环境，准备测试数据，使用AWS的Lambda服务进行各种测试（功能测试和性能测试）。由于测试环境位于AWS的数据中心，因此还需要考虑由哪些研发人员使用测试环境，以及他们所拥有的权限，这就是用户权限的问题。
在发布阶段，则需要准备生产环境，实施增量发布策略，在这个过程中还需要考虑如何在保持已有数据库服务稳定运行的同时升级数据库，升级业务逻辑，最终将数据服务平稳地替换成新的数据库服务而不影响线上用户，这就是我们常说的rolling deployment。由于数据是存储于云端的，因此为了数据安全，则需要为存储在云端的数据进行加密存储以及需要确保数据传输过程也是加密的。为了观察业务增长模式以及性能调优，则需要监控DynamoDB的使用情况，找出哪些数据经常被访问，哪个时间段的数据存储活动最活跃。为了防止运维人员错误地删除数据，则还需要选择合适的策略为数据进行备份。为了防止其他用户读取不相干的信息，则还需要考虑设置数据存取权限，以便某些数据无法被查阅。当遇到某些场景，其要求低延时，比如1微秒以内，那么则还需要考虑使用缓存技术来降低响应延时。当企业开始向海外扩张时，为了让海外用户能够快速地访问数据服务，则需要将数据完整地拷贝到离海外用户地理位置更近的数据中心。有时，你还需要将数据导出到数据分析系统，以便其它部门，比如销售或市场部门能分析这些数据，用于后续的营销活动。
企业的业务在发展过程中会经常遇到以上所提到的问题，为了解决这些问题则需要借助对应的工具。接下来，让我们看看DynamoDB都提供了哪些功能以及集成了哪些服务来解决上述提到的问题。
1.2 DynamoDB与周围的工具 DynamoDB本身提供了数据存取功能，它还考虑了高可用性（所有的数据会自动拷贝到不同的可用区，以免某一个区发生故障了，另外一个区能够及时补上），除此之外，它会将所有数据以加密的方式存储在磁盘（从9.KMS中获取秘钥），而传输过程中则使用了HTTPS协议来加密传输数据。DynamoDB还提供了1.Stream功能，该功能能够捕获数据的变动，因此可以基于这个功能将数据同步到4.其它数据分析系统。如果企业需要海外扩张，那么可以借助DynamoDB的2.Global Table功能。为了避免人为因素引起数据丢失，DynamoDB提供了2种数据备份的方式：分别是按需备份和按时间备份。这些功能均是开箱即用的，也就是说研发人员只需要根据实际的业务场景来组合所需的功能。之前所提到的部分问题均可以迎刃而解！而剩下的一些问题则需要结合一些周围的工具来解决。
使用DynamoDB的初期需要选择合适的数据建模工具：NoSQL Workbench。这个工具是一个可视化工具，有了它，研发人员可以通过可视化的方式数字化建模，定义数据存取模式，查看数据以及操作数据。通过这种方式，数据服务的设计者们可以很快地验证想法。
安装本地版本的DynamoDB对于研发人员来说是非常有必要的，原因在于它能够方便研发人员减少调试数据服务的时间。比如，你用Go语言编写了一个函数，该函数调用了GetItem接口，那么你可以在本地执行单元测试来验证这个函数是否达到预期。安装DynamoDB数据库的方式有很多种，其中通过Docker来启动DynamoDB是一个不错的方法，你要做的只需要安装Docker，之后运行以下指令，就能在本地使用DynamoDB。具体说明可以参考这里。
sudo docker run -p 8000:8000 amazon/dynamodb-local 为了对已有的数据服务调优，比如将经常被访问的数据放到缓存里，首先需要借助DynamoDB提供的10.Contributor Insights功能来查看哪些数据被频繁访问，哪些数据引发了错误，然后还需要启动3.DAX集群服务来缓存这部分数据。DAX集群与DynamoDB无缝连接，它将热数据放到DAX集群机器的内存里，最终从内存里取出数据提供给终端用户。
有时候，有些业务要求返回部分数据，比如对于线上机票业务，用户购买了一张机票，此时该用户只需要知道该机票的登机信息而不需要知道机长等信息。对于这种场景，则借助IAM服务来控制某些数据的访问权限（比如，创建5.Role）。再比如你的所有服务均部署在AWS，且你希望只有AWS中的服务才能访问DynamoDB，那么此时也可以借助IAM服务来支持这种场景。
使用DynamoDB的时候会产生各种信息，有些信息是指标数据：DynamoDB资源的使用情况，有多少请求因为资源不足而无法处理，错误信息，为了得到这些信息，研发人员可以使用7.CloudWatch服务来收集它们。除此之外，还可以创建8.CloudWatch Alarms来判断指标是否超出了一个界限，如果超出则会自动触发一系列操作。还有一些信息是关于操作相关的信息：是谁在什么时间段使用了DynamoDB以及做了什么操作，为了收集这些信息，研发人员可以借助6.CloudTrail服务。
通过以上描述可知，只有将DynamoDB以及周围的服务或工具结合在一起才能打造出一个完整稳定的系统。作为研发者，则只需要根据自身的业务需求来选择是否启用某些服务，比如，如果你的业务不要求微秒级别的响应，那么则没有必要启动3.DAX服务；如果你的业务只是服务于中国的用户，那么2.Global Tables的功能则不需要开启。这里需要注意的是，每种服务的使用都会增加系统的复杂性和费用，因此使用AWS服务的首要原则是按需使用。
1.3 DynamoDB与所处的位置 由上图可知，DynamoDB与许多服务均有交互，如图中的2所示。终端用户（图中的users）通过手机客户端或浏览器访问间接访问DynamoDB，它一方面可以通过https协议来存取数据，另外一方面通过3.DAX来加快存取数据的流程。在存取数据的过程中均会受到5.role的限制，role是属于IAM的一个资源，开发者为其指定哪些人拥有哪些操作DynamoDB的权限以及能存取哪些数据。每次对DynamoDB进行操作，都会产生log信息，这些信息主要分为2类，一类是哪些人做了哪些操作，这些信息存储在6.CloudTrail中，另外一类是关于操作DynamoDB的数据信息，这些信息有哪些数据是热数据，并通过10.Contributor Insights发布到7.CloudWatch中。如果发布到7.CloudWatch中的数据有异常，则会通过8.CloudWatch Alarm发起邮件来通知研发者。如果需要分析DynamoDB中的数据，那么则需要借助1.DynamoDB Stream来将数据导出到4.分析系统，市场人员将通过这个分析系统来生产报告，用于后续的市场推广活动。为了对DynamoDB中的数据加密存储到磁盘，则需要借助9.KMS服务，由KMS提供秘钥原料，并生成key来对数据进行加密。
DynamoDB自身具有自动备份的功能以及同步到不同的区域。区域与区域之间是地理上相互隔离，并通过高速电缆连接起来的数据中心。每一个数据中心除了能防止单点故障（某个区域发生故障后，另外一个区域依然能正常运行）之外，还可以从地理位置上降低服务的响应延时（美国的用户只需要访问美国的Oregon数据中心，而日本的用户则只需要访问Tokyo数据中心）。
作为研发者，在使用AWS服务时，则需要考虑环境的问题。比如，哪些环境是提供给终端用户使用的，哪些环境用于内部测试。比如上图创建了2个账号，分别是security和prod account。其中prod account专门用于生产环境，该环境需要严格把控，尽可能让最少的研发人员操作这个环境，因此需要借助IAM服务来授予部分经验丰富的工程师，授予最少的操作prod account资源的权限。所有研发工作者应该在security account里有对应的IAM User，并通过security来操作prod account中的资源。这种方式确保了每一个环境均是隔离的，且研发工作者的研发账号都得以在security account中统一管理（这种方式称为Across Accounts）。
1.4 DynamoDB的收费模式 DynamoDB从2个方面来收费，分别是 存储 数据所需的费用和 读写数据 所产生的费用。不同区域的单价不同，比如中国香港每个月存储1GB的数据需要花费0.3135美元，而美国的Ohio州则只需要0.25美元。
通常一个快速增长的业务，其存储数据的量很快会达到1TB以上，因此，在Ohio州，每个月存储1TB的数据则需要花费250美元。
DynamoDB提供2种收费模式，分别是on-demand和provisioned capacity。前者是按照请求读写的 次数 来计费，后者则是按照读写单元的 时长 来计费。同样，不同区域的单价不同，比如，选择on-demand模式，在中国香港，每100万条读请求，则需要花费0.31美元，而在Ohio州，则只需要0.25美元。下面让我们基于Ohio州来计算这2种模式的费用。
在 on-demand 模式下，如果每天的读请求是400万次，那么每天的花费将是0.25*4 = 1美元。在相同条件下选择 provisioned capacity模式，其费用为每天0.14美元。从计算结果可知，provisioned capacity模式 似乎 比on-demand模式更加具有价格上的优势，后者是前者的7.</description>
    </item>
    
    <item>
      <title>Terraform、aws-vault和Go实用技巧指南</title>
      <link>https://2cloudlab.com/blog/techniques-for-terraform/</link>
      <pubDate>Sun, 15 Mar 2020 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/techniques-for-terraform/</guid>
      <description>Terraform实用技巧 aws-vault实用技巧 Go实用技巧 组合Terraform、aws-vault和Go工具的实用技巧  本文记录了2cloudlab.com在使用Terraform、aws-vault和Go工具所积累的知识和经验。这些知识和经验是在解决某些问题的时候发现的，如果能够将这些知识和经验汇总，也许能够帮助到其他团队。
Terraform实用技巧  aws_launch_configuration资源是无法通过API来修改的  一个aws_launch_configuration实例创建之后，要想修改该实例的属性，则需要重新创建一个新的aws_launch_configuration实例，原因在于aws_launch_configuration类型的实例是无法通过AWS所提供的API来修改的。
Terraform所提供的所有类别的资源都有一个lifecycle的设置  Terraform工具通过这个设置来决定创建资源的行为。比如以下代码通过设置create_before_destroy = true，最终能够使得Terraform先创建一个aws_launch_configuration新的实例，再将新实例替换掉旧实例，替换成功后再销毁旧实例。lifecycle中的设置只能是常量，因此这种方式：create_before_destroy = var.flag来设置create_before_destroy是不允许的。
resource &amp;#34;aws_launch_configuration&amp;#34; &amp;#34;launch_configuration_instance&amp;#34; { image_id = &amp;#34;ami-0fc20dd1da406780b&amp;#34;#ubuntu 18.4  instance_type = &amp;#34;t2.micro&amp;#34; security_groups = [aws_security_group.instance.id] user_data = &amp;lt;&amp;lt;-EOF#!/bin/bash echo &amp;#34;Hello, 2cloudlab.com&amp;#34; &amp;gt; index.html nohup busybox httpd -f -p ${var.server_port} &amp;amp; EOF# Required when using a launch configuration with an auto scaling group. # https://www.terraform.io/docs/providers/aws/r/launch_configuration.html  lifecycle { create_before_destroy = true } } Terraform提供for_each指令来遍历一个map对象，并根据该对象的键值对each.</description>
    </item>
    
    <item>
      <title>如何通过命令行访问AWS服务-最佳实践</title>
      <link>https://2cloudlab.com/blog/how-to-authority-aws-service-command-line/</link>
      <pubDate>Sun, 15 Mar 2020 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-authority-aws-service-command-line/</guid>
      <description>使用命令行操作AWS服务之前，需要输入登陆凭证。每一个研发人员会经常使用不同账号的登陆凭证来完成他们的工作，比如在测试账号中进行测试工作，在stage账号中部署测试通过的功能等。在现实的工作中，每个研发人员每天平均会操作AWS服务20～50次，而每次都需要给AWS提供登陆凭证。因此为了提高一个团队的研发效率，需要采用一个能够高效访问AWS服务的方法。本文将对比几种方法，并最终给出一个更加有效的方法来访问AWS。
本文将基于以下几种方法来说明如何在类Unix系统上配置和使用登陆凭证：
 将登陆凭证写入配置文件~/.aws/credentials 将登陆凭证写入环境变量AWS_ACCESS_KEY_ID 和 AWS_SECRET_ACCESS_KEY 借助工具aws-valut来设置登陆凭证 总结  将登陆凭证写入配置文件~/.aws/credentials 通过命令行访问AWS服务之前，你需要获得一对登陆凭证，它们的格式如下：
aws_access_key_id=AKIAIOSFODNN7EXAMPLE aws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY 将以上登陆凭证写入~/.aws/credentials文件中就可以轻松访问AWS服务（内容如下所示）。这种方式的最大问题是不安全，因为该登陆凭证是以明文的方式存放，而且容易被别人获取。
[default] aws_access_key_id=AKIAIOSFODNN7EXAMPLE aws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY 既然将登陆凭证存放在磁盘上是不合适的，那么可以通过设置环境变量的方式来解决这类安全问题。
将登陆凭证写入环境变量AWS_ACCESS_KEY_ID 和 AWS_SECRET_ACCESS_KEY 为了不存储登陆凭证，则可以通过写入环境变量的方式来访问AWS服务，如下所示（注意export前的空格）：
echo &amp;#34;Note a space before export command, it will not store used commands in commands history.&amp;#34; export AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE export AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY 以上方式只能在当前运行这些命令的命令行中访问AWS服务，如果该命令行关闭，那么这些环境变量需要重新设置。因此这种方式解决了安全的问题，但是确变得麻烦了。比如我需要打开2个命令行窗口来访问不同的AWS账号。
要想高效访问AWS服务，则应该同时解决以上2个问题。幸运的是，我们可以使用工具：aws-vault来协助我们更好地访问AWS服务。
借助工具aws-valut来设置登陆凭证 aws-valut是一个管理登陆凭证的命令行工具（这篇文章进一步介绍了该工具）。这个工具通过以下方式解决了访问AWS时所遇到问题：
 加密存储登陆凭证 一个命令行同时处理多个登陆凭证 支持所有访问AWS的命令行工具  在使用aws-vault之前，需要设置登陆凭证，比如设置以下2个不同账号的登陆凭证：
aws-vault add slz aws-vault add slz_mfa 比如以下命令使用了slz所对应的凭证并运行aws命令行工具
aws-vault exec slz -- aws iam list-users 以下命令使用了slz_mfa所对应的凭证并运行terraform工具
aws-vault exec slz_mfa -- terraform plan slz和slz_mfa所对应的凭证均以密文的方式存储在磁盘上。通过以上对比，读者应该首先考虑使用aws-vault来访问AWS服务，并考虑在命令行之前加入一个空格来避免命令被记录在历史之中，比如以下示例：</description>
    </item>
    
    <item>
      <title>由amazon.com背后的数据系统所引发的思考</title>
      <link>https://2cloudlab.com/nosql/amazon-back-end-data-system/</link>
      <pubDate>Sat, 14 Mar 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/amazon-back-end-data-system/</guid>
      <description>amazon.com是服务于全球的在线电商，用户在它的平台上购买一件商品所需的时间不超过10秒。它是如何陈列成千上万件商品的同时，依然输出稳定的数据存取性能，从而提升全球用户在购物过程中的体验？对于这个问题的思考，将加深我们对数据库系统的理解，进而设计出优良的数据服务！本文将从Amazon的分类商品和推荐商品问题开始，揭示其背后的数据中心及其构成。紧接着为遇到的问题进行数据建模并分别使用MySQL，MongoDB，DynamoDB技术方案来解决这些问题。每种技术方案都有其适用的场景，并体现在文中，最终形成了一些判断依据，用于决定选择NoSQL还是SQL。
1.1 Amazon的分类商品与推荐商品所引发的思考 下图是从amazon.com首页截取的部分信息，主要包括 分类商品 与 推荐商品 。
  图 1.1 amazon.com主页中部分商品  以上信息有一个特点：每一个大类中均包含多件商品。比如：推荐板块中列举了多件商品；Ride electric类目下有多种商品。这些信息通常会存储在中心服务器上，由数据库系统管理。当用户访问amazon.com时，浏览器会向中心服务器获取商品数据。整个过程如下图所示：
  图 1.2 从数据中心查询商品数据  通过上图可知，数据中心不仅需要存储这些商品信息以及每件商品所属的分类信息，还要提供获取商品信息的方法。为了使数据中心具有数据存取的能力，往往需要引入数据库系统（下图蓝色区域部分）。这些系统不仅能够存储数据，也能够查询数据，通常运行于多台服务器。而这些服务器通过网线连接在一起，作为一个整体对外提供数据存取服务。最终，数据中心的演化如下图所示：
  图 1.3 位于数据中心的数据库系统  注意：以上只是一个简化版的数据中心，现实情况是：amazon.com依赖于多个数据中心，每个国家都会有一个或多个数据中心（比如：美国，欧洲以及中国均有多个数据中心），每个数据中心都有大量的微服务支持着amazon.com。不同国家的用户会直接访问该国家的数据中心，这么做的好处是基于地理位置来降低访问延时。以上简化版的数据中心已经足够让我们讨论大多数amazon.com背后的数据服务了，对于业务遍布全球的企业，多数据中心是必须考虑的。接下来，让我们思考：使用数据库系统存取这些商品信息时会遇到的问题。
首先将遇到问题是：当数据量增多，超过现有的存储能力时，数据如何存储？通常的做法是增加存储空间，比如在每台服务器上挂载多块硬盘。
其次，当每秒访问数据库系统的次数增多时，如何确保数据库系统是有能力提供服务的？解决这个问题的做法是提供多台服务器（每台服务器中运行着数据库软件），并将数据切分成好几份，再将每一份分配到不同的服务器上。
最后，如何确保一次性获取完整的数据（比如一次性获取Ride electric类目下的多种商品）？当所有商品的数据集被切割成更小的集合散落在不同的服务器上时，会出现一种情况：相关联的数据分布在不同的服务器上，为了获取这些数据，则需要从不同的服务器中收集这些数据，最终整合在一起。这种方式存在一个问题：获取相关联的数据所需的时间变长了！因此为了减少获取数据的时间，则需要将相关联的数据集中在一台服务器上，以便一次性将这些关联的数据从一台服务器上取出，而不是多台服务器。为了实现这一目标，则需要一些数据应用的设计经验。
除了以上提到的问题之外，还有其它一些常见的问题需要考虑：如何确保每个分区的数据有多个备份（replica），以便该分区无法提供服务时，另外一个备份接替它的工作？如何解决数据热区的问题（比如一个热销商品被全球60亿人在一秒之内查看）？启动多少台数据库服务器以及如何监控这些服务器的运行状态？如何备份数据，以防人为失误所导致的损失（比如删除所有数据）？如何确保数据中心的温度是正常的，以便服务器能够正常运行？等等。虽然企业在起步阶段不会遇到这些问题，但是随着业务的增长，这些问题将会接踵而至，等待你的是无穷无尽的问题。
如果你开始着手处理以上所有提到的问题，那么你会发现：需要大量有经验的人才和时间以及金钱才能完成，而这种做法是非常糟糕的！好在，现有的云服务厂商，比如中国的阿里云，美国的AWS，Google Cloud以及Azure基本上解决了以上大多数问题！而我们只需要在其基础之上解决一些与业务相关以及技术选型的问题。接下来，让我们基于以上例子来分析有哪些业务问题需要解决，然后选择合适的技术来解决这些问题。
1.2 面临的问题 摆在我们面前的问题有以下2点：
 作为用户，我希望系统能根据历史购买记录来向我展示推荐商品的列表，时间控制在1s以内 作为用户，我希望系统为商品分类，并展示分类商品，时间控制在1s以内  以上问题有很多，分为前端和后端以及数据端，这里要讨论的焦点主要集中在 数据端。为了解决以上2个问题，我们需要对其进行数据建模-数据建模是指将现实世界中的问题抽象成数据实体（data entity）并建立数据实体之间的关系，最终通过计算机来表示。
通过问题的描述可知，共有4个数据实体，它们分别是：用户（User），商品（Product），推荐物（Recommend）以及商品分类（Category），以及3个关系，它们分别是：用户与推荐商品的关系，推荐物与商品的关系和商品分类与商品的关系。整个数据实体以及其之间的关系可以通过下图抽象出来：
  图 1.4 基于SQL的Schema来数据建模  上图实体之间的连线代表它们之间的关系，其中1:*的含义是只1对0或1对多。比如一个用户可以有0，1，或者多个推荐商品。
对面临的问题建立数据模型之后，接下来需要考虑的问题是：技术选型。
1.3 技术选型 在软件行业里，专门针对数据存储与查询的数据库系统有很多，主要分为2大阵营，它们分别是SQL和NoSQL。典型的SQL产品有：MySQL，SQL Server，PostgreSQL等等，而NoSQL的产品有：MongoDB，CouchDB，Dynamo，DynamoDB等等。每种类型的数据库都有其适用的场景，没有一个数据库能够解决所有问题，常见的做法是将这些数据库整合在一起来提供一套数据库系统解决方案。比如SQL数据库产品就特别适合OLAP类型（数据分析）的业务，而NoSQL则适合于OLTP类型（线上交易或即时交互）的业务。比如amazon.com的后台数据系统的构成主要分为3大部分，它们分别是：
 由NoSQL数据库系统组成，并提供在线交易支持的数据服务 由SQL数据库系统组成，并为公司内部提供数据分析服务（ETL） 大数据平台，比如由Hadoop，Spark等框架提供的大数据服务  我们所面临的业务问题属于OLTP类型，因此接下来的内容将围绕OLTP类型的业务问题展开。在展开过程中，我们首先考虑使用SQL数据库系统来解决问题，然后分析这种方法能够带来哪些好处以及什么时候能使用它。除此之外，我们也会分析使用这种方法在哪些条件下会遇到瓶颈以及如何使用NoSQL来解决所遇到的问题。其次，我们会分析NoSQL是如何消除这些瓶颈以及需要为之付出的代价。最后，我们将解释为什么使用DynamoDB而不是其它NoSQL数据库系统。以上提出的第2，3点虽然不属于本文讨论的范围，但是它们在现代互联网企业中依旧占有一席之地，只不过这些问题会随着企业的发展而渐渐浮出水面！
 OLTP=(Online transaction processing)，是指线上交易活动的处理，比如电商，社交网络，搜索引擎等属于这类问题。这类活动有一个特征：低延时。</description>
    </item>
    
    <item>
      <title>如何在DynamoDB中实现排名榜</title>
      <link>https://2cloudlab.com/nosql/leaderboard-write-sharding/</link>
      <pubDate>Fri, 13 Mar 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/leaderboard-write-sharding/</guid>
      <description>在互联网的世界里，你通常会看到一些Top 10事件，比如微博里的Top 10热点事件，领英每年发布的某个行业里最具影响力的Top 20行家，一个图片网站里最受欢迎的Top 100图片等等。你不仅能看到Top 10事件，还会购买一些Top 10热销产品，比如说一些电商网站上好评前10的产品，购买量Top 10的产品等。这些事件或商品有一个特征：Top 10。那么如何利用DynamoDB为这类数据建模呢？如何在海量的事件或者商品里快速找到Top 10的事件或商品呢？这些问题的答案将在下文给出！
本文将介绍如何为DynamoDB中的数据集建立和维护一个积分榜。正如前面所提到的，许多应用场景会使用到积分榜。假设，有一个数据集，你不仅想获取这个数据集中的某项数据，还想根据某个属性获取Top N项数据。
文中的示例是一个图片服务，存储了大量图片&amp;ndash;类似于Unsplash服务。除了要获取单张图片的详细信息，我们还想查看点击数前几的图片。
在整个过程中，你将学到如何将write sharding结合scatter-gather在一起实现这种积分榜。
我想脱帽致敬Chris Shenton，起初是他和我讨论了这种实现积分榜的方法。AWS也在其官方文档里提供了一个在游戏行业中使用积分榜的例子。然而，该例子只针对多个游戏使用了多个积分榜，而不是一个积分榜记录了多个游戏。</description>
    </item>
    
    <item>
      <title>如何在DynamoDB中查询层级结构的数据</title>
      <link>https://2cloudlab.com/nosql/hierarchical-data/</link>
      <pubDate>Thu, 12 Mar 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/hierarchical-data/</guid>
      <description>在本文的示例中，我们将展示如何在DynamoDB中建立具有层级结构的数据（比如树状结构）。这个例子使用了大约25000个星巴克实体店的地址信息。你可以到这里获取源码来动手实践本文所提到的步骤。
层级结构的数据经常在关系型数据库中使用，将数据以树状结构来表示，比如组织架构图或族谱就是这种类型的数据。在关系型数据库中，为了将这些层级结构的数据连接在一起，通常需要使用多个JOINs来完成。而在本文中，我们仅使用一张DynamoDB的表来建立这种数据结构，并提供了更快的查询性能。
 这个例子的灵感来自于Rick Houlihan在2017年的AWS reInvent上的研讨会，感兴趣的读者可以到这里一睹其风采。
 一些关于本文示例的基本信息 假设，我们是星巴克，一家跨国公司，门店遍布全球。现在，我们想把全球所有门店的信息存储在DynamoDB中，并希望能够快速查询以下信息：
 根据门店编号来获取对应的门店信息 列举属于某个国家的所有门店信息 列举一个州或一个省下的所有门店信息 列举一个城市中所有门店信息 列举一个区里所有门店信息  第一种查询模式比较简单&amp;ndash;就是那种key:value的关系，只需要给出门店编号，那么就能取到该门店的信息。剩余的4种查询模式就不是那么容易实现了。 当然，你可以创建4个全局附加索引来分别支持这4种查询模式，也可以使用Filter表达式来过滤出我们想要的数据，但是这2种方法并不高效，同时会消耗更多的读取能力，进而增加费用。
为了解决以上提出的2个问题，我们可以借助该数据的层级信息以及仅使用一个全局附加索引来实现以上4种查询模式！接下来，让我们到Kaggle获取遍布全球的星巴克门店数据&amp;ndash;大约25000条。获取之后需要将这些数据写入到我们的表中，并验证是否完全倒入！以下提到的代码片段摘自这里。
准备工作 为了运行以下示例，你需要下载之前提到的数据，并解压它，然后将CVS文件复制到你的工作目录，名称是directory.csv。除此之外，你还要安装Python以及Boto3框架，该框架是Python版本的AWS SDK。你可以运行指令pip install boto3来按照该框架。最后，有些例子使用了Click框架，该框架能够帮助你快速制定命令行接口，运行指令pip install click来安装它。
设计主键和插入数据 一切就绪之后，是时候创建表以及将数据插入到表中。
首先，为表选择合适的主键。主键应该至少体现以下2点：
 它具有唯一性。也就是它能唯一识别每项数据 它具有均匀分布的特性  理想状态下，主键也需要满足至少一条查询模式。
对于我们要处理的问题，将Store Number作为表的简单主键将是不错的选择。如果我们想要更新某个店铺的信息，那么肯定需要提供该店的Store Number。这符合查询模式的第一项：根据门店编号来获取对应的门店信息。除此之外，Store Number是均匀分布的。
接着，我们需要考虑其余4种查询数据的模式&amp;ndash;如何根据国家，州，城市，区号来获取对应的实体店信息？我们将很快在后面的内容中讨论这个问题，但是现在，我们只需要创建一个全局附加索引&amp;quot;StoreLocationIndex&amp;rdquo;，这些索引需要满足以下要求：
 将Country作为分区键（HASH key），用于指定实体店所在的国家 排序键（RANGE key）为StateCityPostcode，它是一个由State, City和Postcode构成的字符串，其格式为##。例如：一家位于Omaha，NE的店铺，该值应该是：NE#OMAHA#68144。  为了创建这个表，则需要运行以下脚本文件。如果执行成功，则会输出以下信息：
$ python create_table.py Table created successfully! 接下来，将directory.csv文件中的数据加载到DynamoDB中。脚本文件insert_items.py将读取这个文件的数据，然后遍历所有数据项，并将每一项数据插入到DynamoDB中。注意：整个过程需要一些时间，因为大约有25000项数据。
$ python insert_items.py 1000 locations written... 2000 locations written... ... &amp;lt;snip&amp;gt; ... 24000 locations written... 25000 locations written.</description>
    </item>
    
    <item>
      <title>提高研发团队使用AWS服务的效率x100--高效使用aws-vault工具</title>
      <link>https://2cloudlab.com/blog/how-to-authority-aws-through-command-line/</link>
      <pubDate>Tue, 10 Mar 2020 12:29:40 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-authority-aws-through-command-line/</guid>
      <description>在DevOps的世界里有太多工具需要掌握，命令行工具就是其中之一。企业在打造DevOps的过程中会经常使用命令行工具访问AWS服务。一名研发人员每天可能要在命令行里反复（平均50~60次）输入登录AWS的凭证才能创建资源，如果为每一名账号引入安全机制，那么这个登录流程耗时更长！为了减轻这种重复登录所带来的痛苦，则需要一个更加友好的命令行工具来辅助，这个工具就是：aws-vault。
 什么是aws-vault工具 aws-vault工具的使用指南 总结  什么是aws-vault工具 aws-vault是一个命令行工具，这个工具的主要作用在于帮助研发人员以命令行的方式快速访问AWS服务，最终减轻了每一名研发人员因反复登录而带来的负担，从而提高企业整体的研发效率。
aws-vault是一款用go语言编写且开源的命令行工具，其项目地址在这里。aws-vault主要解决安全和自动设置凭证的问题。
初次运行aws-vault时，只需要在命令行里输入如下指令：
aws-vault add slz 根据提示输入AWS_ACCESS_KEY_ID和AWS_SECRET_ACCESS_KEY信息。如果这个凭证具有操作AWS资源的权限，那么研发人员就能通过aws-vault工具高效访问AWS服务。此外，这2个登录信息是以密文的形式存储的，因此aws-vault进一步保护了登录凭证。如果该用户需要使用MFA，那么只需要在文件~/.aws/config加入以下内容：
# config文件 [profile slz] mfa_serial = arn:aws:iam::120699691161:mfa/Tony aws-vault工具会自动到这个文件中读取该MFA地址，并提示研发人员键入6位安全码。如果研发人员需要用到AWS所提供的role，那么也可以按照类似的方式在该文件中添加以下内容：
# config文件 [profile slz] role_arn = arn:aws:iam::120699691161:role/update_role aws-vault工具会自动读取这个role，并自动获取该role所拥有的权限来访问AWS服务。
设置好以上登录凭证之后，研发人员只需要执行以下命令就能自动访问AWS资源:
aws-vault exec slz -- aws iamlist-users 以上命令分两部分：aws-vault exec slz和aws iam list-users。前者会根据slz去找到对应的登录凭证，并自动设置好登录凭证，后者则是使用aws命令行工具列出所有用户信息。后半部分可以是支持AWS凭证登录的任何工具(比如：Terraform工具）。如下例子将aws-vault工具和terraform工具结合在一起使用：
aws-vault exec slz -- terraform apply aws-vault工具的使用指南 完成以上配置之后，接下来看看aws-vault工具如何结合terraform工具使用的。
假设我们使用aws-vault添加了以下具有相同登录凭证，但是不同登录方式的登录选择：
 slz：直接通过登录凭证操作AWS服务 slz_mfa：除了需要登录凭证，还需要输入6位安全码才能操作AWS服务 slz_mfa_role：获取临时登录凭证，并以role的方式访问AWS服务  以下命令说明了如何使用aws-vault工具和terraform plan命令生成资源创建的详细信息:
 以下命令直接通过登录凭证使terraform能够访问AWS服务  aws-vault exec slz -- terraform plan 以下命令与第一种类似，但是在执行访问AWS服务之前需要输入6位安全码  aws-vault exec slz_mfa -- terraform plan 以下命令的登录凭证是临时生成的，所拥有的权限由role来确定，这个role有可能是其它账号的。  aws-vault exec slz_mfa_role -- terraform plan 通过以上命令，研发人员可以快速切换登录场景，并且只需要一行命令就能操作AWS服务。因此对于拥有上百人的研发团队而言，这种便捷能够以100x的系数来提高团队的工作效率！</description>
    </item>
    
    <item>
      <title>DynamoDB Stream</title>
      <link>https://2cloudlab.com/nosql/dynamodb-streams/</link>
      <pubDate>Thu, 05 Mar 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/dynamodb-streams/</guid>
      <description>DynamoDB的表能够存储大量的数据，为了提高查找性能，研发人员通常会将关联但不同的数据实体（比如User和Order）集中存放在一台服务器上，这就导致表中的数据关系难以理解！如果直接基于该表来分析其中的数据，则分析工作将会变得困难起来，除此之外，也会影响终端用户的用户体验（分析任务会占用该表的读写单元）。为了使分析工作变得简单，则需要将表中的数据导入到其它分析系统，最终依赖其它分析系统来分析数据。将数据导出到其它系统主要有2种办法，它们分别是：1.遍历整张表，并将每一项数据写入到其它系统；2.表中的数据每变更一次，则将变更写入到其它系统。前者不适用于数据量庞大的情景，而后者可以很好地避开处理大量数据，但需要借助DynamoDB Stream功能来实现。
DynamoDB Stream是DynamoDB提供的一个功能，现实世界里有许多场景会使用到它，这些场景有：
 同步不同区域的数据。比如你的业务分布在中国和美国，那么你需要将美国的数据同步到中国，反之亦然。此时你需要借助DynamoDB Stream来实现数据同步，最终确保中国用户与美国用户访问的数据是一致的。 发送消息。比如你的App有一个用户注册功能，每当一个新用户注册时，你需要向新用户发送一封表示欢迎的邮件通知。此时你需要DynamoDB Stream的通知机制来触发分发邮件的服务。 索引数据。DynamoDB不适合全文搜索，因此如果你想要搜索表中的数据，那么最好的办法是将表中的数据快速同步到Elastic Search服务或者algolia里，最终通过这些服务来搜索数据。为了能够快速地将数据更新到搜索系统，那么则需要DynamoDB Stream。 聚合或统计数据。有时你想快速得到一些统计信息，比如某个区域的总销量，每家门店每个月所需的成本等等。那么你可以使用DynamoDB Stream来聚合这些数据。  为了实现以上提到的应用场景，则需要了解DynamoDB Stream内部的逻辑以及它与其它服务的关系。这篇文章将从以下几个方面来讲解DynamoDB Stream：
 DynamoDB Stream的构成以及其周边服务 使用DynamoDB Stream的注意事项 基于DynamoDB Stream的设计模式 结论 参考  DynamoDB Stream的构成以及其周边服务 DynamoDB Stream是DynamoDB服务所提供的一个功能，它需要结合DynamoDB Table来使用。开启DynamoDB Stream功能的Table能集成其它服务，最终能够延伸DynamoDB的功能（比如，使用Elastic Search来检索表中的数据，并提供全文搜索功能！）。下图展示了DynamoDB Stream与其它服务的关系：
  图 1.1 DynamoDB Stream与Table，Lambda之间的关系  上图涉及到DynamoDB Stream的工作流程是：
 Producers将向表中修改数据，包括添加数据，修改已有数据，删除数据等。这些操作均是基于HTTPS协议来发起的。 DynamoDB将修改之后的数据写入内部的Transactions Log文件，DynamoDB Stream从该文件中读取更新之后的数据并存放24小时，在这之后，数据将自动从DynamoDB Stream中移除。 Lambda平台向每一个Shard发送HTTPS请求并以poll的方式监听所有的Shards。 Lambda平台从Shard中批量读取新数据（Records），并以Sync的方式启动一个Lambda Function实例，并将Records传入并执行该实例。如果结果返回成功，那么Lambda平台会继续读取下一批数据，失败则把当前的数据集传入该函数实例，并重新执行。  上图涉及到DynamoDB Stream的内部逻辑以及外部交互：
研发人员在使用DynamoDB服务时，需要创建表（Table），每一张表其内部又根据数据量划分了好几个分区（如上图的Partition A，Partition B，Partition C）。每一个分区其实会分布于不同的服务器上。
如果在该表上启用了DynamoDB Stream，那么这个Stream会根据分区数量来创建Shard（如上图有3个Shard）。每一个分区中修改的数据只会发送到对应的Shard上，并且是有序的。每一个Shard里的数据（如上图的Record），其生命周期是24小时，在这之后，该数据项自动移除。
DynamoDB Stream只允许使用者（也就是上图的Consumers）从中批量读取数据，其它操作，比如删除其中的数据项或者修改其中的数据项是禁止的。DynamoDB Stream的吞吐量（MB/S）受到Shard的限制，Shard的数量越多，则其吞吐量越大（每个Shard的吞吐量是2MB/S，每个Consumer每秒最多能读取1MB的数据）。每个Consumer一次最多能从对应的Shard中读取1000条数据（Record）。每个Shard最多同时被2个Consumers来使用，超过这个数量，则会导致读取失败，这一点使得DynamoDB Stream无法直接支持超过2个以上的服务（比如，无法同时支持新用户注册收到欢迎邮件，将数据导出到其它分析系统，检索DynamoDB中的数据等）。
上图使用了AWS Lambda服务作为DynamoDB Stream的Consumers。研发人员只需要创建一个Lambda Function，然后将该Function的触发器设置成DynamoDB，就能接收DynamoDB Stream的通知了。当每个Shard里有新的数据时，Lambda服务会根据该函数的设置（比如最多一次取10000个Records）读取Records（如果Shard里有100万条数据，每1000条的数据量是0.</description>
    </item>
    
    <item>
      <title>DynamoDB的全局附加索引</title>
      <link>https://2cloudlab.com/nosql/global-secondary-indexes/</link>
      <pubDate>Wed, 04 Mar 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/global-secondary-indexes/</guid>
      <description>本文将介绍全局附加索引。与之前介绍本地附加索引的文章一样,我们将涉及全局附加索引的基础知识，然后通过一个例子来使用全局附加索引。
全局附加索引的基础知识 不像本地附加索引，你可以在具有简单主键或复合主键的表中添加全局附加索引。除此之外，你还可以创建具有简单主键的全局附加索引。
以下是列举了全局附加索引的不同之处：
 拥有属于自己的读写单元。当你创建全局附加索引时，你需要单独为该索引分配读写单元。这无疑会增加使用上的复杂程度以及更多的费用，但是同时也给你更加灵活的选择来处理不同模式的读写请求 Eventual consistency。向表中写入一项数据时，这项数据是以异步的方式同步到全局附加索引的。这意味着，当你同时向表和全局附加索引读取同一数据时，其返回结果可能会不一样。而且使用全局附加索引只能选择该选项来同步数据，而无法选择strong consistency来同步数据 同一全局附加索引的分区键能够容纳无限数据。而使用本地附加索引时，这一限制是10GB。 适用于任何表。本地附加索引只能用于具有复合主键的表，而全局附加索引没有这个限制&amp;ndash;你可以将其用于具有简单主键或复合主键的表 可以创建具有简单主键或者复合主键的全局附加索引。  创建全局附加索引 类似本地附加索引，你可以在创建表的时候创建全局附加索引。然而，你也可以在已有的表上创建全局附加索引。如果在已有的表上创建全局附加索引，那么DynamoDB将自动把表中的数据同步到全局附加索引中。
以下示例展示了如何使用全局附加索引建立稀疏索引。稀疏索引的用途是存放一小部分常用的数据，以便提高更快的查找效率！只有那些包含稀疏索引主键的数据才会被同步到稀疏索引中。
假设有一个场景：跟踪用户退货的订单。我们将在这些订单中添加属性ReturnDate，然后将该属性作为稀疏索引的分区键，OrderId属性作为稀疏索引的排序键。
以下创建了该稀疏索引：
$ aws dynamodb update-table \  --table-name UserOrdersTable \  --attribute-definitions &amp;#39;[ { &amp;#34;AttributeName&amp;#34;: &amp;#34;ReturnDate&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34; }, { &amp;#34;AttributeName&amp;#34;: &amp;#34;OrderId&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34; } ]&amp;#39; \  --global-secondary-index-updates &amp;#39;[ { &amp;#34;Create&amp;#34;: { &amp;#34;IndexName&amp;#34;: &amp;#34;ReturnDateOrderIdIndex&amp;#34;, &amp;#34;KeySchema&amp;#34;: [ { &amp;#34;AttributeName&amp;#34;: &amp;#34;ReturnDate&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;HASH&amp;#34; }, { &amp;#34;AttributeName&amp;#34;: &amp;#34;OrderId&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;RANGE&amp;#34; } ], &amp;#34;Projection&amp;#34;: { &amp;#34;ProjectionType&amp;#34;: &amp;#34;ALL&amp;#34; }, &amp;#34;ProvisionedThroughput&amp;#34;: { &amp;#34;ReadCapacityUnits&amp;#34;: 1, &amp;#34;WriteCapacityUnits&amp;#34;: 1 } } } ]&amp;#39; \  $LOCAL 创建全局附加索引的方式类似于本地附加索引。注意：我只需要在--attribute-definitions中添加全局附加索引的属性，以及使用--global-secondary-index-updates选项来指定分区键或排序键。</description>
    </item>
    
    <item>
      <title>DynamoDB的本地附加索引</title>
      <link>https://2cloudlab.com/nosql/local-secondary-indexes/</link>
      <pubDate>Tue, 03 Mar 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/local-secondary-indexes/</guid>
      <description>在之前的文章中，我们学习了附加索引的基础知识。在本文中，我们将深入到本地附加索引。首先，我们将涉及本地附加索引的基础，紧接着通过一个例子来使用本地附加索引。Let&amp;rsquo;s Go!
本地附加索引的基础知识 请注意：你只能在具有复合主键的表中添加本地附加索引。本地附加索引的分区键必须和复合主键的分区键一样，然而允许指定不同的排序键。
一些关于本地附加索引的注意事项：
 本地附加索引的创建必须在创建表的时候添加。也就是说你无法在已经创建好的表上添加附加索引，而是在创建表的时候添加。这一点与全局附加索引不一样 拥有相同分区键，但不同排序键的数据量不允许超过10GB。注意这10GB数据包括表中的数据量加上本地附加索引中的数据量。如果你使用了本地附加索引，那么你得认真考虑使用映射表达式 Consistency选项。对于本地附加索引，你可以像表一样选择strong consistency或者eventual consistency。Strong consistency将占用更多的读单元，但是适用于某些场景 附加索引与表中的读写单元是共享的。也就是说向本地索引读写数据时，会占用表中的读写单元  创建本地附加索引 现在，让我们动手来实践本地附加索引。还记得创建本地附加索引需要在创建表的时候完成吗！因此之前创建的&amp;quot;Users&amp;quot;表不能使用本地附加索引，所以我们只能考虑在&amp;quot;UserOrdersTable&amp;quot;表中添加附加索引。
还记得之前那个根据订单额度来过滤某个用户订单的例子吗？由于订单额度不是主键的一部分，因此我们不得不先根据主键获取该用户的订单，然后再使用过滤表达式来过滤出超过某个额度的订单。
这种需要根据订单额度来过滤数据的模式对于数据量大的场景显然是不适用的&amp;ndash;原因在于，某个用户的订单有很多，比如上万条，而你只需要在这上万条数据中查找几条数据。为了解决这类问题，我们需要建立本地附加索引，并把订单额度作为该索引的排序键。这么一来，根据订单额度来查询订单数据就变快了许多。
虽然本地附加索引能解决以上问题，但不幸的是，创建附加索引必须在创建表的时候指定。不管如何，首先，让我们运行以下指令删除之前的表：
$ aws dynamodb delete-table \  --table-name UserOrdersTable \  $LOCAL 紧接着在创建带有本地附加索引的表：
$ aws dynamodb create-table \  --table-name UserOrdersTable \  --attribute-definitions &amp;#39;[ { &amp;#34;AttributeName&amp;#34;: &amp;#34;Username&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34; }, { &amp;#34;AttributeName&amp;#34;: &amp;#34;OrderId&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34; }, { &amp;#34;AttributeName&amp;#34;: &amp;#34;Amount&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;N&amp;#34; } ]&amp;#39; \  --key-schema &amp;#39;[ { &amp;#34;AttributeName&amp;#34;: &amp;#34;Username&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;HASH&amp;#34; }, { &amp;#34;AttributeName&amp;#34;: &amp;#34;OrderId&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;RANGE&amp;#34; } ]&amp;#39; \  --local-secondary-indexes &amp;#39;[ { &amp;#34;IndexName&amp;#34;: &amp;#34;UserAmountIndex&amp;#34;, &amp;#34;KeySchema&amp;#34;: [ { &amp;#34;AttributeName&amp;#34;: &amp;#34;Username&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;HASH&amp;#34; }, { &amp;#34;AttributeName&amp;#34;: &amp;#34;Amount&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;RANGE&amp;#34; } ], &amp;#34;Projection&amp;#34;: { &amp;#34;ProjectionType&amp;#34;: &amp;#34;KEYS_ONLY&amp;#34; } } ]&amp;#39; \  --provisioned-throughput &amp;#39;{ &amp;#34;ReadCapacityUnits&amp;#34;: 1, &amp;#34;WriteCapacityUnits&amp;#34;: 1 }&amp;#39; \  $LOCAL 以上示例与CreateTable的命令一样。一开始，我们指定了表名，然后增加了2点：(1) 使&amp;quot;Amount&amp;quot;属性作为本地附加索引的排序键；(2) 使用--local-secondary-indexes选项。</description>
    </item>
    
    <item>
      <title>DynamoDB的附加索引</title>
      <link>https://2cloudlab.com/nosql/secondary-indexes/</link>
      <pubDate>Mon, 02 Mar 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/secondary-indexes/</guid>
      <description>到目前为止，大部分的读操作主要是基于表的主键来执行的，要么通过GetItem或者Query完成。使用表的主键来查找数据项是非常高效的一种做法，同时也避免了使用Scan来遍历整张表。
然而，使用主键会限制数据的查询模式。比如，在之前的查询示例中，我们将订单日期作为排序键，使得我们可以根据订单的日期来快速获取某个客户的所有订单。这就意味着我们无法根据订单量来快速获取某个客户的所有订单，因为订单量并不是主键属性。为了解决这个问题，我们可以使用Filter表达式来解决，但是这种办法并不高效，因为Filter是作用在返回的数据集上。那么有什么办法能让返回的数据集就是根据订单数量的大小来决定的？
幸运的是，DynamoDB有一个附加索引的功能，它允许开发者定义其它附加主键，而这些主键可以用于Query（查询）或Scan（遍历）操作。
本文将讨论2种类型的索引，以及使用附加索引的基本规则。
附加索引的类型有几种？ DynamoDB支持2类附加索引，它们分别是：本地索引（local secondary indexs）和全局索引（global secondary indexes）。
本地索引只能创建在具有复合主键的表之上，它的分区键与复合主键的分区键是一样的，但是却使用了不同的排序键。使用本地索引的一种场景是之前根据订单量来获取某客户的所有订单的示例。
全局索引能够创建与表的主键完全不一样的附加主键。比如：你可以在一张具有附加主键的表上使用全局索引来创建简单键，或者你也可以选择与主键完全不同的属性来创建附加的复合主键。当然，如果一张表只有一个简单主键，那么你依然可以使用全局索引来创建附加的复合主键。
附加索引是一个相当有用的功能，它能够衍生出更加高效且灵活的查询模式。
附加索引的基础知识 下面有一些关于附加索引的基础知识是需要知道的：
 附加索引可以不唯一。还记得吗？当我们插入数据时要求该数据的主键是必须唯一的，但是这一条限制不适用于附加索引。因此你可以创建2个具有相同附加索引的数据项（前提是其主键必须不一样）。 附加索引的不一定要提供。当向表中插入数据时，你必须指定主键，而可以不需要提供附加索引的信息&amp;ndash;如果你插入一项新的数据，该数据没有包含索引信息，那么该数据不会添加到索引里，这样的特性使索引变得更加稀疏，常常被称为稀疏索引。稀疏索引有其用武之地，比如建立一个索引搜集所有退货的商品。 每张表的索引数量是有限制的. 每张表最多能创建20个全局索引和5个本地索引  向附加索引中映射属性 当你创建附加索引的时候，你需要指定那些属性是需要映射到即将创建的附加索引。这么做的好处是：当一个基于附加索引的查询执行时，映射好的属性将直接返回，从而避免再次从主表中读取属性信息。
而映射的选项有：
 KEYS_ONLY: 仅映射表的主键信息，比如分区键和排序键以及对应的值 ALL: 将表中完整的数据项映射到该索引 INCLUDE: 选择若干属性映射到该索引  当你建立索引时，要结合查询模式来考虑。DynamoDB会根据索引所存储的数据量来收费，因此将完整的数据项映射将会使你的存储费用变成2倍。而另一方面，你还需要避免查询一次数据需要读取2次表格的情况（一次索引，另外一次是表）。
接下来，让我们进一步了解什么是本地索引。
 原文链接  </description>
    </item>
    
    <item>
      <title>在DynamoDB中使用Filter表达式</title>
      <link>https://2cloudlab.com/nosql/filtering/</link>
      <pubDate>Sun, 01 Mar 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/filtering/</guid>
      <description>在过去的几篇文章里，我们讨论了关键字表达式，条件表达式，映射表达式以及更新表达式。本文将讨论最后一类表达式&amp;ndash;过滤器表达式。
过滤器表达式用于Query和Scan操作，它在作用于这些操作所返回的数据集，并过滤出满足条件的数据项，进而返回给客户端。在深入了解Filter之前，我们有必要来了解一下Query或Scan底层的执行过程。
Query和Scan的执行过程 对于DynamoDB的Query和Scan操作，有3步是需要DynamoDB来完成的：
 从表中查找数据。对于这2类操作，查询将从Starting Token开始，如果在Query中提供了关键字表达式，那么查询的过程中将考虑这类关键字 （这一步是可选的），如果在查询（Query）或遍历（Query）的过程中使用了Filter，那么这个Filter将作用于第一步返回的数据集。同理，映射表达式也是在这一步作用于第一步返回的数据集。 把数据返回给客户端  有一点需要特别注意的是：DynamoDB对返回数据量的限制是由第一步来决定的。比如，如果你在第一步获取100KB的数据，而在第二步使用过滤器将数据量缩减到10KB，那么DynamoDB依然会按照100KB来计算其最终的返回数据量。还需要注意的是：DynamoDB中的任何操作其处理数据的量不能超过1MB，尽管你正在操作的表有充足的读单元。
过滤表达式和映射表达式不是一个高性能的利器-它们不会使你的查询效率变高，然而，它们能帮助你减少数据量，从而最终减少传输带宽的使用。不仅如此，你可以将这些过滤操作逻辑从业务层转移到数据库层。
 关于更多Filter以及什么时候使用它的知识可以参考这篇文章When to use (and when not to use) DynamoDB Filter Expressions。
 如何使用Filter Filter表达式与关键字表达式类似，都可以和Query操作配合&amp;ndash;你只需要在过滤表达式中指定想要过滤的属性，查询结果就会更具该表达式来过滤。
让我们基于之前Query来查找用户&amp;quot;daffyduck&amp;quot;的订单。这一次我们想依据订单额度来过滤数据，比如我们只想返回订单量超过100美元的订单，示例如下：
$ aws dynamodb query \  --table-name UserOrdersTable \  --key-condition-expression &amp;#34;Username = :username&amp;#34; \  --filter-expression &amp;#34;Amount &amp;gt; :amount&amp;#34; \  --expression-attribute-values &amp;#39;{ &amp;#34;:username&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34; }, &amp;#34;:amount&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;100&amp;#34; } }&amp;#39; \  $LOCAL 以下的返回结果只返回了一个订单：
{ &amp;#34;Count&amp;#34;: 1, &amp;#34;Items&amp;#34;: [ { &amp;#34;OrderId&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;20170609-25875&amp;#34; }, &amp;#34;Username&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34; }, &amp;#34;Amount&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;116.</description>
    </item>
    
    <item>
      <title>在DynamoDB中，谨慎使用Scans操作</title>
      <link>https://2cloudlab.com/nosql/scans/</link>
      <pubDate>Fri, 28 Feb 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/scans/</guid>
      <description>本文将介绍DynamoDB的Scans操作。该操作是DynamoDB的重型武器。做一个相似的对比: GetItem操作就是是一对镊子，可以夹出某个特定的物件。Query操作像把铁铲，能挖出一大堆物件，但是其作用的范围依旧很小。然而，Scan操作就像一辆拖拉机，把整个修整区域翻个底朝天。
 在我们深入到Scan操作之前，请记住以下这句话:
 不要使用Scan操作，除非你知道自己在做什么。
 Scan操作作用于整张表。对数据量庞大的表，该操作将耗尽整张表的读取单元。如果你在应用程序里的关键路径里使用它，那么它会增加响应延时。
只有在以下情况下，才会考虑使用Scan操作:
 表的数据量不大 将数据迁移到另外一个数据库系统 you use global secondary indexes in a special way to set up a work queue (very advanced).  带着以上告诫，让我们来探索Scan操作的使用方式。
Scan操作的基础知识 Scan操作是DynamoDB中最容易使用的功能。开发者只需要在执行该操作时提供表的名字，它就能帮你返回表格中所有数据项（返回的数据量不超过1MB）：
$ aws dynamodb scan \  --table-name UserOrdersTable \  $LOCAL 以下是返回结果（为了方便阅读，其中省略了中间部分）：
{ &amp;#34;Count&amp;#34;: 25, &amp;#34;Items&amp;#34;: [ { &amp;#34;OrderId&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;20160630-28176&amp;#34; }, &amp;#34;Username&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34; }, &amp;#34;Amount&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;88.3&amp;#34; } }, ... { &amp;#34;OrderId&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;20171129-28042&amp;#34; }, &amp;#34;Username&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;alexdebrie&amp;#34; }, &amp;#34;Amount&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;83.</description>
    </item>
    
    <item>
      <title>如何在DynamoDB高效查询多项数据</title>
      <link>https://2cloudlab.com/nosql/querying/</link>
      <pubDate>Thu, 27 Feb 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/querying/</guid>
      <description>在DynamoDB中，查找操作的功能十分强大。它允许开发者根据相同的分区键来查询拥有不同排序键的数据项。本文将介绍查询操作的基础知识，分为以下几部分：
 根据某个分区键查找多项数据 基于排序键和使用关键字表达式来查询多项数据 使用映射表达式来选择要返回的属性信息  当继续后续的学习之前，你需要理解什么是DynamoDB的表达式。
根据某个分区键查找多项数据 在之前的章节里，我们实践了如何一次操作一项数据。这种操作适合于一些场景，比如：一次操作一个用户信息，这些信息可能是该用户的简介或姓名。
然而，在某些场景，这样的数据操作就不适用了，比如操作用户的订单。有时你可能只需要获取某个订单数据，但是，有的时候我们想获取某个用户的所有订单信息。如果每个订单的信息由不同的分区键识别，那么查找这些订单的效率会很慢。
接下来，让我们看看有什么更好的办法能够快速查找某个用户的所有订单。答案是使用Query操作，首先，我们的场景是获取用户为&amp;quot;daffyduck&amp;quot;的所有订单信息。注意：--key-condition-expression选项是非常关键的参数，这个参数定义了我们如何选择要返回的订单。如下所示：
$ aws dynamodb query \  --table-name UserOrdersTable \  --key-condition-expression &amp;#34;Username = :username&amp;#34; \  --expression-attribute-values &amp;#39;{ &amp;#34;:username&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34; } }&amp;#39; \  $LOCAL 运行以上指令将得到4个属于&amp;quot;daffyduck&amp;quot;的订单，如下所示：
{ &amp;#34;Count&amp;#34;: 4, &amp;#34;Items&amp;#34;: [ { &amp;#34;OrderId&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;20160630-28176&amp;#34; }, &amp;#34;Username&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34; }, &amp;#34;Amount&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;88.3&amp;#34; } }, { &amp;#34;OrderId&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;20170608-10171&amp;#34; }, &amp;#34;Username&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34; }, &amp;#34;Amount&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;18.</description>
    </item>
    
    <item>
      <title>如何在DynamoDB中同时操作多项数据</title>
      <link>https://2cloudlab.com/nosql/working-with-multiple-items/</link>
      <pubDate>Wed, 26 Feb 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/working-with-multiple-items/</guid>
      <description>在过去的章节里，我们一次只能操作一项数据&amp;ndash;比如插入，查找，更新以及删除单项数据。而在这篇文章里，我们将一次同时操作多项数据。从这章开始，我们将创建一张具有复合主键的表，并在该表中同时操作多项数据。
复合主键对于DynamoDB而言非常有用。它允许你通过一个查询操作就能获取一组相关的数据项，除此之外，它还有其它强大的用途。
本文将创建一张具有复合主键的表。然后我们将使用BatchWriteItem API来批量生成多项数据。后续的几篇文章将使用Query和Scan API作用到这些数据。
创建表 创建一张具有复合主键的表与创建一张具有简单主键的表类似，都需要定义属性和key schema。不同的是，你需要指定2个属性构成复合主键，而不是1个。 然后你需要指定其中一个属性是分区键，另外一个属性是排序键。
分区键决定了你的数据是如何划分的，而排序键则决定了具有相同分期键的数据项是有序的。分区键尤其重要-当使用Query操作时，你只能使用分区键。分区键与排序键组合在一起可以建立一对多的数据模型-因为一个相同的分区键下，可以有多个不同的排序键。
每当需要基于复合主键来对数据建模时，可以根据以下句子来填写空格处，最终构建正确的查询模式：
 &amp;ldquo;Give me all of the ____ from a particular ___.&amp;rdquo;
 放入第一个空格的属性应该是排序键，而放到最后一个空格的属性则是分区键。在以下示例中，我们将创建一张即包含User类型数据，同时也会包含Order类型数据的表：&amp;ldquo;UserOrdersTable&amp;rdquo;，其中每个User可以包含多个Orders。按照以上句子来构建查询模型，其最终的结果是：&amp;ldquo;返回该Username的所有OrderIds&amp;rdquo;。基于这句话，可以得出：Username是分区键，而OrderId则是排序键。
为了创建&amp;quot;UserOrdersTable&amp;rdquo;，需要使用CreateTable API：
$ aws dynamodb create-table \  --table-name UserOrdersTable \  --attribute-definitions &amp;#39;[ { &amp;#34;AttributeName&amp;#34;: &amp;#34;Username&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34; }, { &amp;#34;AttributeName&amp;#34;: &amp;#34;OrderId&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34; } ]&amp;#39; \  --key-schema &amp;#39;[ { &amp;#34;AttributeName&amp;#34;: &amp;#34;Username&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;HASH&amp;#34; }, { &amp;#34;AttributeName&amp;#34;: &amp;#34;OrderId&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;RANGE&amp;#34; } ]&amp;#39; \  --provisioned-throughput &amp;#39;{ &amp;#34;ReadCapacityUnits&amp;#34;: 1, &amp;#34;WriteCapacityUnits&amp;#34;: 1 }&amp;#39; \  $LOCAL 返回的结果如下所示：</description>
    </item>
    
    <item>
      <title>更新和删除数据项</title>
      <link>https://2cloudlab.com/nosql/updating-deleting-items/</link>
      <pubDate>Tue, 25 Feb 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/updating-deleting-items/</guid>
      <description>在这篇文章中，我们将学习如何向表中更新和删除单项数据。这是最后一篇关于单项数据操作的文章，后续的文章将涉及多个数据项的操作，这些操作主要有Queries和Scans。
更新单项数据 在之前的例子中，我们使用PutItem操作来向表中插入单项数据。我们也看到这种操作将会完全覆盖表中已存在的数据。为了不让这个操作覆盖已存在的数据项，我们在这个操作上使用了条件表达式。
有时需要处理这种场景：只更新某项数据的一个或者多个属性，而其它属性保持不变。为了处理这种场景，DynamoDB提供了UpdateItem操作，该操作允许开发者在不读取数据的情况下更新数据。
当使用UpdateItem操作时，你需要指定更新表达式，该表达式由2部分构成，分别是：更新的语义（比如是向数据项中添加属性还是移除属性）和表达式。
当使用更新表达式时，你必须提供以下更新的语义：
 SET: 这个操作用于向数据项中添加新的属性，或者覆盖已有属性 REMOVE: 该操作用于移除数据项中某一个属性 ADD: 对于数值类型的属性，该操作代表加或减；对于集合类型的属性，该操作代表向集合中插入元素 DELETE: 用于从集合中删除元素  让我们通过几个例子来了解更新操作的使用。
 使用带有SET语义的UpdateItem  在更新数据项时，最常用的更新操作是SET。比如，如果我想向某项数据添加一个新的属性或者覆盖已有的属性，那么这个SET操作会被用到。
让我们看看最开始的例子：PutItem，假设，我们想让已经添加的用户拥有属性DateOfBirth。 如果不使用UpdateItem操作，我们的做法是首先通过GetItem获取该数据项，然后通过PutItem插入一项包含DateOfBirth属性的数据项。然而通过UpdateItem操作，我们只需要直接插入属性DateOfBirth即可，如下所示：
$ aws dynamodb update-item \  --table-name Users \  --key &amp;#39;{ &amp;#34;Username&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34;} }&amp;#39; \  --update-expression &amp;#39;SET #dob = :dob&amp;#39; \  --expression-attribute-names &amp;#39;{ &amp;#34;#dob&amp;#34;: &amp;#34;DateOfBirth&amp;#34; }&amp;#39; \  --expression-attribute-values &amp;#39;{ &amp;#34;:dob&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;1937-04-17&amp;#34;} }&amp;#39; \  $LOCAL 注意我们使用了选项--expression-attribute-names和--expression-attribute-values。
如果我们再次获取该数据项，那么我们不仅能看到之前的属性，而且还能看到新添的属性，如下所示：
$ aws dynamodb get-item \  --table-name Users \  --key &amp;#39;{ &amp;#34;Username&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34;} }&amp;#39; \  $LOCAL { &amp;#34;Item&amp;#34;: { &amp;#34;Username&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34; }, &amp;#34;DateOfBirth&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;1937-04-17&amp;#34; }, &amp;#34;Age&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;81&amp;#34; }, &amp;#34;Name&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;Daffy Duck&amp;#34; } } }  使用带有REMOVE语义的UpdateItem  带有REMOVE语义的UpdateItem操作与带有SET语义的UpdateItem操作相反&amp;ndash;它用于从一个数据项中删除指定属性。</description>
    </item>
    
    <item>
      <title>DynamoDB的基础表达式</title>
      <link>https://2cloudlab.com/nosql/expression-basics/</link>
      <pubDate>Mon, 24 Feb 2020 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/expression-basics/</guid>
      <description>本文是关于DynamoDB的表达式。表达式是DynamoDB的内置功能，它又细分为以下几类表达式：
 条件表达式只能与单项数据的操作配合起来使用，这些操作有PutItem，UpdateItem和DeleteItem。当你为单项数据的操作指定条件表达式时，只有当该表达式的验证结果为true时，该操作才能执行，对应的指令选项是--condition-expression 属性映射表达式通常会与读取数据项的操作配合起来使用，比如之前的GetItem例子就使用了属性映射表达式，它的作用在于仅返回该项数据的部分属性，对应的指令选项是--projection-expression 更新表达式用于更新已经存在的数据项上的某些属性，对应的指令选项是--update-expression 主键条件表达式通常会与查询操作（比如Query）一起使用，这类表达式的条件只能是与主键相关，对应的指令选项是--key-condition-expression 过滤表达式通常会与查询操作或遍历操作一起使用，它将作用于查询结果之上，对应的指令选项是--filter-expression  只有充分理解了这些表达式，才能更好地使用DynamoDB，进而享受DynamoDB给我们带来的好处。在这篇文章，我们将学习表达式的基础知识，包括使用表达式的属性名和属性值。紧接着，我们将基于上一章关于PutItem的例子来学习如何使用条件表达式。
表达式的基础知识 DynamoDB中的表达式只是一串字符串，它的内容是特定的逻辑表达式，而这个表达式将用来验证数据是否满足该条件。在这些表达式中，你可以应用一些比较操作符，比如&amp;quot;=&amp;rdquo;（相等），&amp;ldquo;&amp;gt;&amp;rdquo;（大于）或者&amp;quot;&amp;gt;=&amp;rdquo;（大于等于）。例如，以下表达式应用了&amp;quot;&amp;gt;=&amp;rdquo;：
&amp;#34;Age &amp;gt;= 21&amp;#34; 该表达式的作用在于：该操作只能作用于年龄在21岁及以上的用户，否则操作结果会出错。
 注意：以上表达式还无法生效，原因在于该表达式没有指定&amp;quot;21&amp;quot;的类型。为了使以上表达式生效，你需要指定expression attribute values，也就是使用指令属性--expression-attribute-values，这一点将在后面提到。
 除了可以在表达式中使用比较操作符，还可以在表达式中使用函数。这些函数是DynamoDB提供的，它们有：attribute_exists()，判断某项数据其属性是存在的；attribute_not_exists()，判断某项数据其属性是不存在的；begins_with()，判断某项数据其属性值是以某个子字符串开始的。
我们可以在表达式中使用attribute_not_exists()函数来判断某个订单是否已经发货了，其用法如下所示：
&amp;#34;attribute_not_exists(DateShipped)&amp;#34; 如果该订单有DateShipped属性，那么表明它已经发货了，否则表明它还在仓库中。DynamoDB提供的函数不多，所有的函数如下所示：
 attribute_exists(): 判断某项数据其属性是存在的 attribute_not_exists(): 判断某项数据其属性是不存在的 attribute_type(): 判断某项数据其属性的类型是指定的类型 begins_with(): 判断某项数据其属性值是以某个子字符串开始的 contains(): 如果该属性是字符串类型，则判断某项数据其属性值是包含某个子字符串的；如果该属性是集合类型（比如List或Map），则判断该属性是包含指定元素的 size(): 返回属性的大小，不同类型的属性，其大小的计算规则是不一样的。  关于表达式中的比较操作符和函数，读者可以参考官方文档。
表达式的占位符 之前的内容表明，表达式是一个具有逻辑运算的字符串，DynamoDB通过执行这个表达式来得到一个是或否的结果。然而，有的时候你需要一种更加清晰的方式来编写表达式，比如在表达式中使用变量，然后在其它地方提供变量值。
DynamoDB允许你使用--expression-attribute-names和--expression-attribute-values选项来编写更加清晰的表达式。通过这种做法，你可以在表达式中指定变量，然后分别使用以上选项来指定变量值，DynamoDB会将这些变量值自动替换掉表达式中的变量。接下来，让我们看看这2个选项的含义。
 --expression-attribute-names  有时，你希望针对一个属性编写表达式，但是由于DynamoDB的限制，你无法直接在表达式中使用该属性名，比如：
 你的属性名称刚好是DynamoDB中预留的关键字。DynamoDB预先保留了大量的关键字，其中包括了：&amp;ldquo;Date&amp;rdquo;，&amp;ldquo;Year&amp;quot;和&amp;quot;Name&amp;quot;等。如果你的属性名称恰巧在这些预留的关键字里，那么你需要借助这个选项来提供属性名称的占位符 你的属性名称中包含&amp;rdquo;.&amp;quot;。DynamoDB使用&amp;rdquo;.&amp;ldquo;来获取嵌套类型（比如Map类型）中的子项。如果你的属性名中包含了&amp;rdquo;.&amp;quot;，那么你需要借助这个选项来提供属性名称的占位符 你的属性名称开头包含数字。DynamoDB不允许表达式中的属性名称以数字开头，因此如果你的属性名称以数字开头，那么你需要借助这个选项来提供属性名称的占位符  在使用这个选项时，你只需要提供一个Map格式的属性名称集合。这个Map中的key是表达式中的占位符，而value是属性名称。例如，你可以为&amp;quot;Age&amp;quot;属性定义占位符&amp;rdquo;#a&amp;rdquo;，而这个占位符可用于表达式，具体示例如下所示：
--expression-attribute-names &amp;#39;{ &amp;#34;#a&amp;#34;: &amp;#34;Age&amp;#34; }&amp;#39;  当使用--expression-attribute-names时，占位符必须以&amp;rdquo;#&amp;ldquo;开头。
 在之前的GetItem的例子中，我们使用了--projection-expression选项来返回某项数据的部分属性。为了能够在该选项中使用占位符，我们需要将之前的例子改如下：
$ aws dynamodb get-item \  --table-name Users \  --projection-expression &amp;#34;#a, #u&amp;#34; \  --expression-attribute-names &amp;#39;{ &amp;#34;#a&amp;#34;: &amp;#34;Age&amp;#34;, &amp;#34;#u&amp;#34;: &amp;#34;Username&amp;#34; }&amp;#39; \  --key &amp;#39;{ &amp;#34;Username&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34;} }&amp;#39; \  $LOCAL { &amp;#34;Item&amp;#34;: { &amp;#34;Username&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;daffyduck&amp;#34; }, &amp;#34;Age&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;81&amp;#34; } } } 注意，在以上例子中，我们在--projection-expression中使用了2个占位符，分别是&amp;rdquo;#a&amp;quot;和&amp;rdquo;#u&amp;rdquo;。而这2个占位符定义在--expression-attribute-names选项中，分别对应&amp;quot;Age&amp;quot;和&amp;quot;Username&amp;quot;属性。</description>
    </item>
    
    <item>
      <title>让产品7*24小时持续服务于用户--在线更新产品功能</title>
      <link>https://2cloudlab.com/blog/how-to-rolling-deploy-online/</link>
      <pubDate>Sat, 15 Feb 2020 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-rolling-deploy-online/</guid>
      <description>当企业对外发布产品的新功能时，如何保证原有的功能不受影响，仅替换需要升级的功能？企业无法接受在线服务暂时性停止对外服务。试想想，几十万用户正在使用某个软件产品，突然因为企业的一次功能升级，导致几十万用户无法正常使用，最终造成企业损失。幸运的是，在软件行业，有几种方案可以解决这类问题。
方案一:blue/green deployment。这种方案的思想是维持2套相似的运行环境，其中一个环境运行当前产品，另外一个环境运行带有新功能的产品，一旦带有新功能的产品能够正常工作了，就将用户流量导入新环境， 并保留原来的环境(以免新环境发生严重问题时，可以及时切换到原来稳定的环境上)。这种方案的好处是实施起来简单，而且可以及时恢复到最新的稳定环境上，但是它增加了成本(需要同时运行2套相似的运行环境)，增加了工作量(需要同时管理2套相似的运行环境)。整个过程如下图所示:
方案二: rolling deployment。这种方案的思想是增量替换，先启动新功能，将流量从原有功能导入到新功能上，保持原有功能，直到新功能正常工作才关闭原有功能。持续以上步骤，直到新功能逐一替换掉原有功能。这种方案的好处是无需维护2套资源，降低成本，但是其缺点是增加了实施的复杂度。除此之外，该方案也有局限性，它适用于由大量微服务组成的分布式系统。整个过程如下图所示:
方案三: canary deployment。这种方案在rolling deployment的基础之上加入了一些特性。比如根据用户的特征(国家、性别、年龄等)来确定一小部分群体，并向该群体发布新功能。这种方案进一步增加了实施的复杂性，好处是对外发布时，其作用的范围，粒度更细了。
每种方案都有适用的场景，因此企业需要根据实际情况选择其中一个来解决在线更新产品功能的问题。</description>
    </item>
    
    <item>
      <title>Go编程的奇幻之旅（一）基础知识</title>
      <link>https://2cloudlab.com/blog/how-to-use-go-to-develop-part1/</link>
      <pubDate>Sun, 15 Dec 2019 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-use-go-to-develop-part1/</guid>
      <description>本文将指导你如何准备Go研发环境以及介绍一些基础语法知识。这些内容能够帮助你快速地在企业中应用Go语言所带来的好处。这些好处有：跨平台、丰富的三方库、并发和内置自动化测试功能。本文将按照以下几个方面来介绍Go：
 下载和安装Go 选择IDE Go常用的命令 Go的内置类型 流程控制 并发 错误处理 结构化数据的转化 导入第三方模块 总结  下载和安装Go 在使用Go编程时，首先需要下载和安装Go研发环境。读者可以到其官方网站下载。下载完成之后是安装Go研发环境，假设安装路径为/path/to/go。
安装完成之后需要配置环境变量GOROOT，根据不同的平台设置环境变量的命令是不一样的，如下所示：
 Linux和macOS平台  export GOROOT=/path/to/go  Window平台  setx GOROOT &amp;#34;\path\to\go&amp;#34; 环境变量GOROOT的作用是告诉系统Go语言的安装路径，以便当执行go命令时能够找到可执行性文件。除了要设置GOROOT，还需要设置环境变量GOPATH。Go所提供的工具集依赖于GOPATH，所有源码、三方库以及编译好的程序都会在GOPATH所指定的目录下。假设在macOS运行以下指令：
export GOPATH=$HOME/gocode 那么你的所有源码都需要放在src目录下，因此，你需要在目录$HOME/gocode中创建文件夹src。除了使用src目录放置Go源码，在目录$HOME/gocode中还需要创建目录bin和pkg。此时的目录结构是：
gocode ├─bin ├─pkg └─src bin放置所有可执行性文件；pkg放置Go程序所依赖的3方库；src放置了你即将编写的Go程序。
以上步骤操作完成之后，需要执行以下命令来进一步确保Go运行环境安装正确！
$ go version go version go1.11.5 linux/amd64 选择IDE 在开始编写Go程序之前，需要根据自身的情况来选择IDE。以下是一些常用的IDE，使用这些IDE能够提高编程效率！
 Vim Editor GitHub Atom Microsoft Visual Studio Code  选择IDE之后，需要为其配置调试环境，这里以VS Code为例来配置调试环境，其它IDE也需要配置对应的调试环境。为了能在VS Code里调试Go代码，则需要安装以下插件:
 VSCode-Go plugin   Analysis工具 Delve  安装完成之后需要按照以下方式配置Go-Plugin，其中program填写Go程序所在的目录。
 接下来将举2个例子来说明如何调试，其中一个例子是调试Go程序，另外一个例子是调试自动化测试用例。</description>
    </item>
    
    <item>
      <title>如何为产品提供可信度较高的运行环境</title>
      <link>https://2cloudlab.com/blog/how-to-test-terraform-code/</link>
      <pubDate>Fri, 15 Nov 2019 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-test-terraform-code/</guid>
      <description>在企业中经常会发生此类事情：临近产品新功能发布的日子，企业上下忙的不可开交，甚至有些研发人员被半夜叫醒解决新功能无法使用的问题，大家急急忙忙将遇到的问题解决了却又引发了其它问题，最终导致产品新功能无法及时发布或者产品运行在一个容易奔溃的环境。这类事件反复发生，使得研发人员害怕产品新功能的每一次发布。这种害怕将导致企业延长新功能的发布周期，本来一周一次的发布计划改成了一个月一次发布。更长的发布周期将会积累和隐藏更多的风险和不确定因素，因此这类事件变得更加常见，问题变得更加糟糕！面对这个问题所带来的挑战，企业需要缩短发布周期来及早暴露和解决问题，而缩短发布周期的关键点在于如何在短时间内发现更多的缺陷！自动化测试是实现这个关键点的因素之一。
自动化测试在产品的研发过程中无处不在。研发团队在研发产品时需要为其编写单元测试；测试团队在测试产品时要为其编写手动测试、集成测试和UI测试；DevOps团队需要为产品的运行环境编写自动化测试用例，确保生成的环境是稳定且支持产品的。为产品研发实施自动化测试的目的在于短时间内发现和解决更多的缺陷，从而增强产品对外发布的信心！本文将通过以下方面来介绍如何对产品的运行环境进行自动化测试，企业可以根据自身情况，引入本文所提到的自动化测试经验来确保产品的运行环境是可信的。
 2cloudlab模块的自动化测试 静态检测Terraform的编码 针对Terraform模块编写单元测试（Unit Test） 针对Terraform模块编写集成测试（Integration Test） 针对Terraform模块编写端到端的测试（End-to-End Test） 为测试环境中的资源定制清除策略 总结  其中单元测试、集成测试和End-to-End测试需要使用Go语言来编写大量测试代码，产品运行环境的质量主要由它们来保证。这些测试的难易程度、数量占比和运行时间由下图所示：
 2cloudlab模块的自动化测试 2cloudlab的模块都会包含一些自动化测试用例。每一个Terraform模块都会有对应的测试用例，这些测试用例会放在一个test目录下（目录结构如下所示），每一个测试用例所验证的场景是不同的。由于这些自动化测试用例都是用Go语言来编写的，因此需要使用Go语言的运行时环境来运行。除此之外，为了能够高效地编写自动化测试用例，需要引入第三方工具Terratest，该工具也是基于Go语言来编写的（这篇文章介绍了Go语言的基础知识），它像一把瑞士军刀，提供了大量通用的基础操作。
. |____examples | |____iam_across_account_assistant | | |____main.tf | | |____outputs.tf | | |____README.md | | |____terraform.tfstate | | |____terraform.tfstate.backup | | |____variables.tf |____modules | |____iam_across_account_assistant | | |____main.tf | | |____outputs.tf | | |____README.md | | |____variables.tf |____test | |____iam_across_account_assistant_test.go | |____README.md 其中test目录下的测试用例iam_across_account_assistant_test.go会调用examples下的手动测试例子来验证目录modules下的Terraform模块iam_across_account_assistant。
2cloudlab根据以上目录结构编写了大量的单元测试以及少量的集成测试。这些测试是遵守了以下原则来编写的:
 每一个测试用例都会基于真实环境来执行 每一个测试用例执行结束后都会销毁已创建的资源 为每一个资源指定一个独立的命名空间，以免发生名称冲突 每一个测试用例都会在独立的临时目录下下运行 为每一个集成测试添加可配置stage步骤 测试用例之间是相互独立且可并发执行  在编写测试用例之前，有一步关键的验证：静态检测。为Terraform模块实施静态检测只需要花费几分钟，但是确能够避免一些常见的错误，接下来让我们从静态检测开始来一步一步提高产品运行环境的稳定性！</description>
    </item>
    
    <item>
      <title>如何正确使用2cloudlab.com的服务</title>
      <link>https://2cloudlab.com/blog/how-to-use-2cloudlab-services/</link>
      <pubDate>Tue, 15 Oct 2019 12:21:58 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-use-2cloudlab-services/</guid>
      <description>企业在为软件产品提供运行环境时需要做的事情太多了。这些事情有安装软件、配置软件、创建服务器、准备数据库、监控等等。如果每一件事情都需要手动去完成，那么效率是低下的，而且容易出错！在2cloudlab，我们试图通过自动化的方式处理以上事情。因此2cloudlab提供了各种可重复使用的模块，通过组合这些模块以及依赖计算机执行这些模块来加速产品运行环境的生成！2cloudlab致力于让企业在一天之内创建完整的软件运行环境。
 创建一个完整的产品运行环境的任务列表 如何使用2cloudlab所提供的Terraform模块 如何构建infrastructure_modules 如何构建infrastructure_live 在infrastructure_modules中引用2cloudlab的Terraform模块 在infrastructure_live中引用infrastructure_modules 总结  创建一个完整的产品运行环境所需的任务列表 创建一个完整的产品运行环境需要考虑的事情太多了，这些事情有：
 安装：安装产品以及其依赖项（比如准备操作系统） 配置：为软件提供配置信息，这些信息有端口设置、数据库密码等 创建资源：为软件创建运行环境，这些环境由计算资源、存储资源以及其它资源构成 部署：将软件部署到运行环境，在线更新功能等 高可用性：考虑在多个区域启动相同服务，确保任何一个区域停止工作时，其它区域依然能够提供服务 可扩展：支持横向扩展（增加或减少资源来应对高峰期或低峰期）和纵向扩展（增强资源） 性能：优化产品运行环境的性能，包括CPU、GPU和内存 网络：配置IP、端口、VPN、SSH 安全：增加数据安全（包括传输和存储安全）、网络安全 指标监控：收集有价值的数据，通过KPI的方式呈现出来 日志监控：收集用户日志以及产品运行环境日志 备份和恢复：支持数据备份和恢复，支持运行环境快速恢复 成本优化：降低产品运行环境的使用成本 文档：为产品代码编写文档，为产品编写说明书 测试：编写测试用例、自动化测试、集成测试和产品测试  为产品准备运行环境都会遇到以上问题，企业需要根据实际情况来选择哪些事项是需要实施的，哪些事项当下是不需要实现的。以上事项如果都使用手动的方式来实现，那么结果将会是令人失望的。2cloudlab针对这些事项实现了一个个可复用的模块，用户只需要组合并使用这些模块就能轻松地创建出开箱即用的解决方案。2cloudlab所提供的模块经过大量的测试，并可以帮助企业在一天之内完成环境的准备。接下来让我们看看如何使用2cloudlab所提供的模块。
2cloudlab所提供的Terraform模块 2cloudlab基于Terraform编写了可复用的模块，这些模块主要托管在github上。每个模块的格式如下所示：
. |____examples | |____iam_across_account_assistant | | |____main.tf | | |____outputs.tf | | |____README.md | | |____variables.tf |____modules | |____iam_across_account_assistant | | |____main.tf | | |____outputs.tf | | |____README.md | | |____variables.tf |____README.md |____test | |____README.md | |____iam_across_account_assistant_test.go  modules目录下包含了子功能，用户将引用这个目录下的子功能来完成环境的搭建 examples目录下包含了如何使用modules目录下子功能的例子以及对应的说明文档 test目录主要测试了modules目录下的子功能 README.</description>
    </item>
    
    <item>
      <title>如何使用Serverless来快速推出产品</title>
      <link>https://2cloudlab.com/portfolio/how-to-promote-with-serverless/</link>
      <pubDate>Mon, 12 Aug 2019 16:58:55 +0600</pubDate>
      
      <guid>https://2cloudlab.com/portfolio/how-to-promote-with-serverless/</guid>
      <description>Introduction AWS Lambda was launched at re:Invent 2014. It was the first implementation of serverless computing where users could upload their code to Lambda. It performs operational and administrative activities on their behalf, including provisioning capacity, monitoring fleet health, applying security patches, deploying their code, and publishing realtime logs and metrics to Amazon CloudWatch.Lambda follows the event-driven architecture. Your code is triggered in response to events and runs in parallel. Every trigger is processed individually.</description>
    </item>
    
    <item>
      <title>企业如何在一天之内部署线上服务--高效使用terraform</title>
      <link>https://2cloudlab.com/blog/how-to-apply-terraform-across-entire-enterprises/</link>
      <pubDate>Mon, 15 Jul 2019 12:29:40 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/how-to-apply-terraform-across-entire-enterprises/</guid>
      <description>terraform是一个用go语言编写的跨平台、开源、只有单个运行文件的命令行程序。terraform通过解析和执行terraform configuration文件集合，最终会在短时间内生成分布式软件所运行的环境，避免了手动配置环境，减少出错的可能性。在企业里，要想高效地使用terraform来正确且快速地生成分布式软件所运行的环境，不仅需要掌握terraform知识，还需要结合工程方面的实践经验（比如版本控制，模块划分，测试）以及其它工具（比如Packer、Docker、Kubernetes）来共同实现。
这篇文章将通过以下话题来说明如何在企业中高效使用terraform：
 企业为何使用Terraform？ Terraform的运行机制 如何解决多人同时使用Terraform的问题 在企业中建立Devops团队以及Terraform规范 现实世界中DevOps团队的工作内容 总结  企业为何使用Terraform？ Terraform的主要作用在于基于云服务提供商创建资源和准备运行环境。企业内部需要借助不同工具推行DevOps，Terraform就是其中之一。软件产品或服务都需要运行在一个特定的环境上，因此企业需要为软件准备这些运行环境，而这些运行环境的准备就是需要工具：Terraform。除此之外还有其它工具（比如CloudFormation），企业之所以使用Terraform工具的原因在于：
 拥有强大而且活跃的社区支持、免费和开源 支持大部分云服务提供者（AWS、Azure、GCP以及其它云服务） 只需要一个terraform运行文件和云服务厂商的账号就能在自己的电脑上使用 terraform是基于描述型语言（declarative language）来定义资源的最终状态 terraform支持一致性部署（immutable infrastructure）,每次更新均是可重现且一致的  随着云计算的普及，企业应该使用云计算带来的好处&amp;ndash;降低成本和应用更加先进的技术&amp;ndash;来使自己处于行业领先位置。使用Terraform可以以Infrastructure as Code的方式使用云服务，DevOps人员只需要编写脚本、安装Terraform可执行文件、一个云服务商账号以及执行脚本的一台电脑就能远程为软件创建资源和准备环境。这些脚本文件由版本控制系统进行管理，这样一来软件工程方面的经验便可应用在这些脚本文件上。要想高效使用Terraform，除了要学习Terraform知识，还要解决多人使用的情况。在这之前，以一个简单的示例来了解Terraform的运行机制是一个良好的开端。
Terraform的运行机制 terraform是单文件命令行程序，它基于infrastructure as code方式来运行的，因此需要给terraform提供脚本文件让其运行。脚本文件的后缀是.tf，其中的内容涉及选择云服务提供商、创建何种类型的资源以及定义输入输出变量等等。
在开始运行terraform之前，需要准备以下条件:
 一台笔记本电脑 根据操作系统下载对应的terraform可执行性文件，并把该文件所在位置添加到系统的环境变量中 到AWS注册一个根账号，并用根账号创建一个子账号，这个子账号会被terraform使用 将子账号生成的ID和Key提供给terraform  以上步骤准备好之后，接下来编写以下terraform脚本文件:
# main.tf  terraform { required_version = &amp;#34;&amp;gt;= 0.12, &amp;lt; 0.13&amp;#34; } provider &amp;#34;aws&amp;#34; { region = &amp;#34;us-east-2&amp;#34;# Allow any 2.x version of the AWS provider  version = &amp;#34;~&amp;gt; 2.0&amp;#34; } resource &amp;#34;aws_instance&amp;#34; &amp;#34;example&amp;#34; { ami = &amp;#34;ami-0d5d9d301c853a04a&amp;#34; instance_type = &amp;#34;t2.</description>
    </item>
    
    <item>
      <title>如何构建企业级AWS账号体系</title>
      <link>https://2cloudlab.com/portfolio/how-to-construct-enterprise-accounts/</link>
      <pubDate>Fri, 12 Jul 2019 16:58:55 +0600</pubDate>
      
      <guid>https://2cloudlab.com/portfolio/how-to-construct-enterprise-accounts/</guid>
      <description>当使用AWS作为基础服务为分布式软件产品提供资源时，需要做的事情太多了。有时需要查看使用AWS服务的费用、有时需要在dev环境中测试研发的功能、有时需要在stage环境中模拟prod环境的运行情况、有时需要在prod环境中上线新功能。如果研发团队里有100人都能对AWS进行各种个样的操作，那么后果是非常混乱不堪的：比如，有些成员的操作导致prod环境奔溃了、有些成员完成测试时忘记销毁资源最终导致费用变高、甚至没有察觉外来攻击者使用了企业的AWS资源等。为了杜绝这些情况发生，企业在使用AWS服务之前，需要为研发团队构建一套有效的AWS账号体系。本文将围绕如何构建企业级AWS账号体系展开，最终提供一套可实施的方案。
 为何构建企业级AWS账号体系 构建企业级AWS账号体系的基本思想 一天之内构建企业级AWS账号体系的操作指南  为何构建企业级AWS账号体系 使用AWS服务前，我们需要到AWS官网注册一个账号。通过这个账号就可以使用AWS提供的各种服务，比如：EC2、S3、CloudWatch等。由于一个研发团队由多人组成，因此需要为每一个团队成员准备一个AWS账号。为了能够有效地管理这些账号，此时需要构建一个账号体系，这个账号体系的作用如下：
 隔离  使用不同的AWS账号能够将不同的环境（dev、stage、prod）独立开来，以免任何一个环境出问题了不会影响其它环境。隔离不同的环境能够带来这些好处：外来攻击者登陆到了stage环境，而prod环境依然得到了保护；研发人员修改stage环境，prod环境的依然正常工作。
安全  构建有效的账户体系能够统一管理用户。管理员能够轻松地在一个集中的地方为所有用户启动密码策略（比如密码的长度、密码组成的字符类型等）、MFA认证（比如短信或邮箱校验码通知）、定期修改密码等。除此之外，研发人员的权限控制粒度更细了。比如管理员可以方便地为研发人员赋予某个环境下某些具体的权限。
记录与报告  一个有效的账户体系能够记录所有人员的操作历史。在一个有效的账户体系下，任何用户的任何操作都会留下记录，并统一存储在一个集中的地方。除此之外，如果有外来者入侵，那么他们的操作和行踪也会被记录下来，以便查明漏洞。使用AWS服务会产生费用，那么一个有效的账户体系能够集中生成各个环境的费用情况，包括每个环境的各个资源的细节，避免了漏算的情况。
以上提到的好处是建立在一个有效的账号体系下的。要想更加顺利地研发产品的前提是：建立一个有效的账号体系。接下来，让我们看看一个企业级AWS账号体系应该是怎样的。
构建企业级AWS账号体系的基本思想 构建AWS账号体系能够带来诸多好处，因此企业在研发初期就应该构建这种账号体系。构建一个有效的AWS账号体系的方案有很多，接下来本文将提出一个可实施并且简单的企业级AWS账号体系解决方案，其设计思路如下图所示：
 上图的账号体系是分步构建的，每一步基本上围绕Users、Groups、Role以及Policy展开。这些组件（Users、Groups、Role以及Policy）是由AWS的IAM（Identity and Access Management）服务提供的，用户可以基于IAM服务来构建安全的用户访问机制。通过手动方式来创建企业级AWS账号体系无疑是具有挑战的，这种方式不仅容易出错，而且时间漫长，因此需要一种自动化的方式来解决这些挑战。2cloudlab所提供的across_account_assistant模块能够帮助企业快速且正确地构建企业级AWS账号体系。接下来让我们看看每一步所涉及的具体内容。
 创建root账号，并用root用户登陆  在开始使用AWS服务的时候，需要使用邮箱来注册一个账号，这个账号就是上图最上面的root账号。使用root账号登陆的用户就是root用户，这个用户能够做任何事情（包括删除用户、创建各种资源、创建子账号等等）。创建root账号的作用主要有以下2方面：
 创建其它子账号，这些子账号里的Users能够创建和使用云资源；创建组以及每组成员（full_access和billing） 统一管理所有子账号使用云服务而产生的费用。  因此root用户需要创建2组人员：一组是管理人员（组名为full_access），他们负责创建和管理子账号；另外一组是财务人员(组名为billing)，他们负责管理费用。创建组的同时，需要指定哪些用户属于哪个组，这些操作步骤可以通过点击AWS的UI页面完成，但是这种手动方式容易出错而且十分耗时，因此推荐使用2cloudlab所提供的across_account_assistant模块来创建（最多需要一天就能建立完整的企业级AWS账号体系）。为了使billing组的用户能够访问账单相关的页面，需要root用户主动启动IAM访问账单的设置，具体设置如下（点击用户名，选择&amp;quot;My Account&amp;rdquo;，滑动到以下内容，将“Activate IAM Access”勾选并点击“Update”）：
 在创建组full_access和billing以及对应的成员之后，需要降低入侵root账号的风险。具体的操作方式为：为root用户开启MFA验证，其不能用于研发并需要安全放置，只允许少部分人知道，删除所有root用户相关的命令行方式登陆凭证，定期更换密码。从此之后退出root账号，转而用full_access的成员登陆并用于后续操作。
使用full_access的成员登陆AWS之后，首先要做的事情是：创建cloud trail服务（推荐使用2cloudlab所提供的模块来创建），该服务是为了跟踪所有用户使用资源的情况，以便出问题的时候可以根据这些跟踪的信息定位问题发生的原因。其次需要创建organization服务，并使用organization服务创建security、dev、stage、prod和shared-service子账号。每一个子账号都有对应的邮箱，这个邮箱所对应的用户就是该子账号下的root用户。为了登陆这些子账号，需要重制每个子账号下root用户的密码。重制完成之后，需要登陆到各个子账号完成后续的构建。
注：root账号和root用户是不同的概念。每个账号下可以有多个用户，包括root用户，具有相同权限的用户可以分在同一组。企业只有一个root账号，而且不同企业需要根据自己的实际情况创建对应的子账号，以上给出的例子适用于大多数中小型企业。对于大型企业，则需要考虑在organization服务下创建Unit，每一个Unit对应一个事业部，需要重复创建以上子账号。
以root用户的方式登陆security账号  在security账号下，主要创建管理组(full_access)和其它组（across_account_dev_*、across_account_stage_*等）。管理组的主要作用在于管理security账号，只允许一部分人加入这个组；其它组的作用在于允许其成员访问其它子账号(比如dev、stage和prod)。企业应该根据实际情况来建立其它组，常见的划分依据有根据职能来划分。比如：across_account_dev_developers_access、across_account_dev_testers_access的组成员能够分别以研发和测试权限访问dev子账号。所有用户都会创建在security账号中，这种方式统一了用户管理。其它子账号则只需要建立对应的role就能够被security账号下有权限的用户访问。
security账号下的所有用户都不会在该账号下创建资源，反而会通过其它子账号中role来在其它子账号（dev、stage、prod）创建资源。建立其它组的时候需要用到其它子账号（dev、statge和prod）的role arn，因此需要在其它子账号中创建对应的role，并将role arn提供给其它组。接下来是stage账号的构建。
以root用户的方式登陆stage账号  stage账号中不存在用户，只有role，这些role根据角色来确定权限（比如：可以为研发人员创建这个role：allow_dev_access_from_other_account，该role允许来自其它账号的用户在stage账号中创建一小部分资源）。其它子账号（dev和prod）也只能创建role，并通过role授权给其它账号（比如security）的用户。因此，构建dev和prod账号的过程与构建stage账号的具体过程是一致的。其中要注意的是，dev、stage、prod这些子账号是不允许创建分组和用户的。在stage子账号中创建role的过程主要分以下3步：
 为role选择一个名字，并创建role 为该role指定trusted policy，该policy的作用是指定能够使用该role的其它账号（比如security账号，通过12位的ID来识别） 为该role指定permission policy，该policy的作用是限制这个role能够在stage账号中使用哪类资源以及对其所执行的操作  为了在其它子账号中使用stage子账号中创建的role，则需要在其它账号中授予用户权限（比如在security子账号中为across_account_dev_developers_access赋予访问allow_dev_access_from_other_account的权限，这一步通过为across_account_dev_developers_access指定inline policy完成）。
在stage账号中创建其它role的过程类似，为了一次性完成stage账号中所有role的创建，推荐使用2cloudlab所提供的across_account_assistant模块来辅助。dev、prod、shared-service等账号也需要按照类似的方式创建对应的role。
当完成对所有子账号的构建之后，需要将root用户的登陆方式限制，只允许其通过网站的方式登陆子账号，并且将所有命令行登陆的凭证删除。
在root账号中创建CloudTrail服务  到目前为止，你已经在root、security、dev、stage、prod、shared-service和test账号中创建了对应的IAM user、IAM group、IAM role和IAM policy。研发人员便可以使用自己的账号登陆AWS服务，并根据自己拥有的权限创建对应的资源。为了能记录每一位用户使用AWS服务的情况，则需要创建CloudTrail服务。该服务可以记录每一名用户使用AWS服务的踪迹，并将这些信息归档到AWS的S3服务。开启cloudtrail的好处是：可以及时通过归档的记录来调查外来入侵者的踪迹，从而修复安全漏洞。</description>
    </item>
    
    <item>
      <title>在DynamoDB中插入和读取数据项</title>
      <link>https://2cloudlab.com/nosql/inserting-retrieving-items/</link>
      <pubDate>Sat, 23 Feb 2019 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/inserting-retrieving-items/</guid>
      <description>数据项是DynamoDB的基础单元，每一张表都会包含多项数据。接下来，在本文中，我们将向DynamoDB中插入和读取数据项。我们将创建Users表，并为该表指定一个简单键：Username。接着，我们将操作2个基本的接口：PutItem和GetItem。下一篇文章，我们将在这篇文章的基础上应用表达式来实现更加复杂的查询功能。在这之后，我们将另起一篇文章来讲解如何更新和删除数据项。
 为了能顺利操作本文所列举的示例，请确保DynamoDB的环境已经准备好。注意：如果你使用的是本地版本的DynamoDB，那么请确保$LOCAL变量配置正确，如果使用的是AWS上的DynamoDB，那么在每一个命令后面无需追加这个参数。
 创建表 在演练本文列举的用例之前，首先需要创建一张表。我们将创建一张表&amp;quot;Users&amp;rdquo;，并为该表定义了一个简单主键：&amp;ldquo;Username&amp;rdquo;，它的类型是string。
当创建表时，你需要为主键或索引提供属性定义。这些属性定义包含了属性名和属性类型。在Users这张表中，我们使用&amp;quot;Username&amp;quot;作为主键，其类型是string（&amp;ldquo;S&amp;rdquo;）。除此之外，你还需要为该表定义KeySchema，其中指定了哪些属性构成主键以及这些属性是HASH键还是RANGE键。在以下示例中，属性&amp;quot;Username&amp;quot;构成了该表的简单主键。最后，你需要指定表名和表的吞吐单元，其中吞吐单元由读和写单元构成。在以下示例中，&amp;ldquo;Users&amp;quot;表的读写单元都是1，简单来说，越多的读写单元，单位时间内读写数据的速度越快和越多，反之亦然！
有了以上概念, 让我们运行以下指令来创建表&amp;quot;Users&amp;rdquo;:
$ aws dynamodb create-table \  --table-name Users \  --attribute-definitions &amp;#39;[ { &amp;#34;AttributeName&amp;#34;: &amp;#34;Username&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34; } ]&amp;#39; \  --key-schema &amp;#39;[ { &amp;#34;AttributeName&amp;#34;: &amp;#34;Username&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;HASH&amp;#34; } ]&amp;#39; \  --provisioned-throughput &amp;#39;{ &amp;#34;ReadCapacityUnits&amp;#34;: 1, &amp;#34;WriteCapacityUnits&amp;#34;: 1 }&amp;#39; \  $LOCAL 如果创建表的操作成功了，你将看到以下返回结果：
{ &amp;#34;TableDescription&amp;#34;: { &amp;#34;TableArn&amp;#34;: &amp;#34;arn:aws:dynamodb:ddblocal:000000000000:table/Users&amp;#34;, &amp;#34;AttributeDefinitions&amp;#34;: [ { &amp;#34;AttributeName&amp;#34;: &amp;#34;Username&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34; } ], &amp;#34;ProvisionedThroughput&amp;#34;: { &amp;#34;NumberOfDecreasesToday&amp;#34;: 0, &amp;#34;WriteCapacityUnits&amp;#34;: 1, &amp;#34;LastIncreaseDateTime&amp;#34;: 0.</description>
    </item>
    
    <item>
      <title>DynamoDB中，每项数据（item）的构成单元</title>
      <link>https://2cloudlab.com/nosql/anatomy-of-an-item/</link>
      <pubDate>Fri, 22 Feb 2019 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/anatomy-of-an-item/</guid>
      <description>DynamoDB中的每条数据是构成整个数据集的基础，它对应着关系型数据库中的某一张表中的某一行数据或者对应MongoDB中一个文档，又或者是编程当中的一个对象（比如一个用户对象）。每条数据由主键唯一标识，而主键是在创建表的时候指定的。除了主键之外，每条数据也可以包含其它属性，这些属性与主键组成了一条完整的数据单元（比如：一个用户数据由user_id, name, phone组成，其中user_id是主键）。每个属性（包括主键）都有对应类型，比如string，numbers，lists，sets等，当写入或查询数据的时候，这些类型都需要提供。在这篇文章中，我们将通过以下几个方面来讨论构成每项数据的基础单元：
 主键 属性 属性的类型  主键  表中的每项数据都由主键唯一标识
 每当创建一张表的时，你需要为该表指定一个主键。每项数据由主键唯一标识，而且每当向表中插入一项数据时，该项数据必须包含主键信息。
Dynamo支持2种主键。一种是简单主键，这种主键只使用了一个属性标识每一项数据，比如用户名或者订单编号。使用简单主键来写入或查询数据时有点类似于key-value数据库，比如Memcached。另外一种是复合主键，这种主键使用了2个属性来标识每一项数据。其中一个属性是分区键，它的作用在于将不同的数据划分到对应的分区。另外一个属性是排序键，它的作用是使所有具有相同分区键值的数据依据排序键进行排序。拥有复合主键的表，除了能够支持简单的写入和查询数据操作，还支持更多复杂的数据查询操作。
理解DynamoDB中表的主键对于数据建模至关重要。每当插入和更新数据时，主键都是必不可少的信息。
属性 每项数据都由多个属性构成，比如User表中的某一项数据有Name，Age，地址等属性，这些属性类似于关系型数据库中的列。DynamoDB表
DynamoDB表中每一项数据除了必须包含主键属性，其它属性不是必须的。DynamoDB是NoSQL数据库，因此它允许更加灵活的数据模型，而这一点在关系型数据库中是无法办到的。因为这种灵活的数据模型，你能在一张DynamoDB表中存储多种不同类型的数据，比如有一条Car数据，它包含产地，型号和生产年限等属性，同时在相同的表中也包含另外一条Pet数据，它包含类型，血型，年龄，颜色等属性。在DynamoDB中，一张表中同时包含不同类型的数据是常见的做法，这种做法会提高数据查询的效率！
属性的类型 当为每一项数据设置属性时，同时需要指定该属性的类型。可指定的类型有简单类型：比如，strings和numbers；也有复合类型：比如：lists，maps和sets。
每当更新或者插入数据时，需要为数据中的每一个属性指定其对应的类型。这些属性的设置需要借助一个map数据结构来完成，其中该map的keys是每一个属性名，而对应的values则是另外一个map，而这个map只有一个元素，其key是对应属性的类型，而value是对应属性的值。比如：你想存储一个用户数据，该数据包含3个属性，分别是姓名，年龄和角色，它们的类型分别是string，number和list，那么你需要为该用户数据设置如下属性信息：
{ &amp;#34;Name&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;Alex DeBrie&amp;#34; }, &amp;#34;Age&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;29&amp;#34; }, &amp;#34;Roles&amp;#34;: { &amp;#34;L&amp;#34;: [&amp;#34;Admin&amp;#34;, &amp;#34;User&amp;#34;] } } 在以上例子，我们存储了Name属性，其类型是string（通过&amp;quot;S&amp;quot;来代表），值为&amp;quot;Alex DeBrie&amp;rdquo;。此外，还存储了Age属性，其类型是number（通过&amp;quot;N&amp;quot;来代表），值为&amp;quot;29&amp;rdquo;。最后，还存储了Roles属性，其类型是list（通过&amp;quot;L&amp;quot;来代表），值为&amp;quot;Admin&amp;quot;和&amp;quot;User&amp;rdquo;。
同样，每当你从表中获取数据项时，其属性会以map的方式返回。其中，map中的keys是属性名，而values则是另外一个map，这个map的key是对应属性的类型，而value则是对应属性的值。例如，如果你使用GetItem API来获取以上用户数据，那么得到的结果如下所示：
{ &amp;#34;Item&amp;#34;: { &amp;#34;Name&amp;#34;: { &amp;#34;S&amp;#34;: &amp;#34;Alex DeBrie&amp;#34; }, &amp;#34;Age&amp;#34;: { &amp;#34;N&amp;#34;: &amp;#34;29&amp;#34; }, &amp;#34;Roles&amp;#34;: { &amp;#34;L&amp;#34;: [&amp;#34;Admin&amp;#34;, &amp;#34;User&amp;#34;] } } }  需要注意的是：Age属性的值&amp;quot;29&amp;quot;是字符串，因此为了得到数值类型29，那么需要在应用程序里将字符串转成数值类型。
 对以上属性类型有一些基本了解之后，让我们来看看不同的属性类型。每种属性类型都会以类型标识（比如&amp;quot;S&amp;quot;代表string，而&amp;quot;N&amp;quot;代表number）和用例开始介绍。</description>
    </item>
    
    <item>
      <title>NoSQL的学习资料</title>
      <link>https://2cloudlab.com/nosql/additional-reading/</link>
      <pubDate>Thu, 21 Feb 2019 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/additional-reading/</guid>
      <description>这篇文章收录了一些关于NoSQL的英文资料。有的解释NoSQL为何能规模化而SQL却受到限制；有的涉及NoSQL的单表设计原则，以及解释为何需要使用单表；其中有一篇文章是关于如何将SQL中多张有关联的表转化成DynamoDB中的单张表。还有一些关于DynamoDB的视频资料，其中的内容讲述了NoSQL的设计原则，以及如何高效使用DynamoDB。读者可以通过这些学习资料来掌握NoSQL的理论知识，通过这些知识来设计既能支持100TBs以上数据又能输出稳定性能的数据应用方案。
文章:  SQL, NoSQL, and Scale: How DynamoDB scales where relational databases don&amp;rsquo;t - This is a post of mine explaining the core architectural decisions that allow NoSQL databases to scale further than their SQL brethren. The What, Why, and When of Single-Table Design with DynamoDB - A deep look at what it means to do single-table design in DynamoDB and why you would want to. It also includes a few situations where you may want to avoid single-table design.</description>
    </item>
    
    <item>
      <title>企业为何需要在内部推广Devops</title>
      <link>https://2cloudlab.com/blog/devops-cicd-infrastructure-as-code/</link>
      <pubDate>Thu, 21 Feb 2019 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/blog/devops-cicd-infrastructure-as-code/</guid>
      <description>企业对外发布产品之前其在内部需要做好各种准备：研发工程师完成产品研发，测试工程师完成产品测试，DevOps工程师部署产品。在这个过程中遇到任何问题，都会影响产品的发布，因此企业在数字化转型的过程中都需要优化这一流程。在软件行业中，优化这个流程的方法论是：DevOps。
这篇文章接下来将围绕以下内容来介绍DevOps：
 DevOps在企业内部推广的现实状况 对企业有价值的DevOps是什么样的？ 如何理解：Devops、CICD、Infrastructure as code Infrastructure as code的优势 总结  DevOps在企业内部推广的现实状况 DevOps在中国区企业的推广令人堪忧。大多数企业只实现了DevOps的持续集成部分，比如研发人员提交代码会触发服务器自动编译生成软件产品、测试人员的测试脚本会自动执行并验证软件产品的缺陷。很少有企业能够把发布产品这一部分做好，比如DevOps人员运行基础资源脚本来准备环境、部署产品、监控产品、植入安全机制、优化基础资源等。有部分企业甚至都没有这个概念。下面列举了我经历的一些企业遇到的关于DevOps的问题。
 大多数企业都没有一个完整DevOps团队 企业对DevOps的理解是不一样的，最终导致没有统一的DevOps方案 企业对产品发布的认知只是停留在“能用就行”的程度，如何优化、监控、保护基础环境并不重视 云计算的使用经验匮乏 缺乏DevOps的实施经验  没有实施DevOps的企业将面临一个问题：产品无法及时推向市场。
对企业有价值的DevOps是什么样的？ 在企业内部，研发工程师根据产品经理的需求，在自己的电脑上完成编码、测试、Code Review并最终提交代码并完成产品功能的研发。理想情况下，这些功能会第一时间交付到客户，并为其带来价值。DevOps就是为实现这个流程而提出来的。对企业而言，DevOps的价值在于及时为客户输出高质量的产品，最终为客户创造价值。这一简单的目标背后实际上是由一系列相关的活动所支撑的。让我们看看现实世界中，软件从研发到发布所涉及的工作事项。
阶段一：研发团队根据需求研发产品功能，这个过程涉及编码、测试、提交源码；阶段二：测试团队获取研发团队的成果并进行测试，这个过程涉及到准备测试环境、执行各种测试、生成测试报告；阶段三：DevOps团队获取测试团队验证过的产品并发布产品，这个过程涉及到准备运行环境、监测产品运行状态、实施安全机制、优化资源使用情况。
这些工作事项好似被串联到一条流水线上，由不同角色共同在这条流水线上完成产品的研发、测试和交付，最终把产品及时发布到线上，以供客户使用。因此流水线的流畅性决定了企业响应市场的能力，在软件行业中，这条流水线就是业内常说的CICD。企业开始数字化转型时就应该考虑搭建CICD的策略，因为搭建CICD是一个漫长的过程，期间需要不断地迭代，同时也会涉及到多个团队。试想想，如果福特没有汽车生产流水线，那么福特公司也就无法生产大量的汽车了，同样，在软件行业中，CICD也起到了类似的作用，只不过这条虚拟的流水线生成的是高质量的软件产品。
实施CICD的基础是自动化。也就是说企业需要为研发和发布产品引入自动化机制，而Infrastructure as code是实现自动化的一种方式。它要求研发和发布产品过程中所涉及的工作事项要通过代码的方式驱动。计算机只需要执行这些代码就能完成产品的测试和发布，从而实现自动化。
如何理解：Devops、CICD、Infrastructure as code 在软件行业中，Devops, CICD, Infrastructure as code几个词汇经常出现，它们的最终目标是帮助企业提高软件质量同时向市场推出杀手锏产品。以下是来自wiki的定义：
Devops的定义
 DevOps is a set of practices that combines software development (Dev) and information-technology operations (Ops) which aims to shorten the systems development life cycle and provide continuous delivery with high software quality.</description>
    </item>
    
    <item>
      <title>DynamoDB的环境搭建</title>
      <link>https://2cloudlab.com/nosql/environment-setup/</link>
      <pubDate>Wed, 13 Feb 2019 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/environment-setup/</guid>
      <description>DynamoDB是一个完全托管于AWS的NoSQL解决方案。开发者可以选择直接在AWS上创建一个DynamoDB的表或者将DynamoDB安装到本地。后续的内容将涉及DynamoDB的API，比如通过AWS CLI来操作DynamoDB。为了操作DynamoDB，我们需要搭建DynamoDB的环境。
安装 AWS CLI AWS CLI是AWS提供的命令行工具，开发者通过使用这个工具能够方便地使用AWS所提供的云服务，包括DynamoDB服务。运行以下命令来安装AWS CLI：
$ pip install awscli 如果在安装过程种遇到困难，可以参考这里进行安装。
获取认证和授权 如果你打算使用AWS提供的DynamoDB服务，那么你需要正确地设置认证和授权的权限，具体需要参考官方文档。
比较简单的一种方式是授予开发者所有关于DynamoDB操作的权限，其策略定义如下：
{ &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;dynamodb:*&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; } ] } 一旦你在AWS上申请了一个账号并得到了能够操作DynamoDB的凭证，那么你还需要将这个凭证通过以下方式设置到本地电脑
$ aws configure AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY Default region name [None]: us-west-2 Default output format [None]: json 在本地搭建DynamoDB服务 AWS提供了可在本地运行的DynamoDB，它可以在本地运行，免除了凭证的设置和避免了使用云端DynamoDB所产生的费用。
想要在本地使用DynamoDB，那么根据以下指令下载和安装DynamoDB：
$ curl -O https://s3-us-west-2.amazonaws.com/dynamodb-local/dynamodb_local_latest.zip $ unzip dynamodb_local_latest.zip $ rm dynamodb_local_latest.</description>
    </item>
    
    <item>
      <title>关于Dynamo的论文</title>
      <link>https://2cloudlab.com/nosql/the-dynamo-paper/</link>
      <pubDate>Tue, 12 Feb 2019 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/the-dynamo-paper/</guid>
      <description>在2004这一年，Amazon.com的增长速度很快，最终其Oracle上的数据规模达到极限，限制了其业务的发展。为了摆脱这种限制，Amazon开始考虑建立他们自己的数据库（注意：在公司内部搭建一个数据库系统是非常糟糕的想法）。在研发自家的数据库之后，亚马逊的工程师创建了创造了Amazon Dynamo数据库，这个数据库支撑了大部分Amazon.com业务，包括其购物车。
那些研发Amazon Dynamo数据库背后的工程师于2007年发布了关于Dynamo的论文。这篇论文描述了这群工程师在搭建高可用，key-value存储过程中为了满足Amazon.com业务场景所学到的经验。
这篇论文影响深远，并催生一大批NoSQL的解决方案，这些解决方案包括Apache Cassandra(最初由Facebook研发)和AWS提供的 SimpleDB以及DynamoDB（注意AWS团队和Amazon团队是2拨不同的团队，2者互不关联）。2012年，Amazon Web Services对外发布了DynamoDB，该服务借鉴了Dynamo的经验和原则，且完全托管在AWS上。
 想要了解为何DynamoDB存储100 TBs以上的数据，却依然能保持稳定的性能? 请参考这篇文章 SQL, NoSQL, and Scale: How DynamoDB scales where relational databases don&amp;rsquo;t。
 Dynamo的几个关键点 非关系型数据模型
关系型数据模型可以用来为不同类型的数据建模（比如针对一个电商的用户和订单来建模）。通常，使用关系型数据建模的方式为数据建模，需要将关联的数据拆分成更小的数据单元，以便这些数据是不重复的，这就是关系型数据库中著名的第一范式。其做法是，如果某类实体数据想要使用另外一类实体数据（比如将订单和用户关联），那么只需要将2类不同的实体数据存储在不同的表格，然后通过外键的方式来关联这2类数据以及通过JOIN操作来拼接和获取这2类数据。此时，你只需要修改某个实体（比如某个用户的用户名），那么另一个数据实体（比如订单所属的用户名也发生了变化）所引用的数据也会因此而变化。
然而，Amazon.com工程师在收集数据库需求时发现了一个非常有趣的结果：
 大约70%对数据库的操作是key-value类型，这些操作仅仅使用主键来获取单条数据。大约20%的操作会返回一个数据集，但是这些数据集均来自于同一张表。
&amp;ndash; Werner Vogels, A Decade of Dynamo
 以上发现是问题的关键 &amp;ndash; 90%的操作不会使用JOIN功能，而这一功能却是关系型数据库的核心。
JOIN操作非常消耗资源。当面对大规模的数据时，工程师通常会将数据复原为一个整体(拒绝使用第一范式)来避免使用JOIN操作而导致的高延时。 通过这种方式来降低响应延时的代价是增加了应用的复杂性&amp;ndash;此时应用程序需要考虑数据的完整性而不是数据库本身。
Amazon.com的工程师已经采用了以上方法来降低延时。实际上，正是意识到亚马逊工程师所需的并不是关系型数据模型，才使得Dynamo设计师重新评估关系型数据库的其它方面。
可用性比数据一致性更加重要
大部分关系型数据库使用strongly consistent model来操作数据。简而言之，这种模式会使得所有客户端在同一时间能够获得相同的数据(想想这个场景:一个用户正在写数据，而多个用户正在读这个写的数据)。
让我们通过Twitter作为例子. 假设2:30PM，Bob在Virginia 发布了一条关于猫的信息。在信息发布之后，有2个用户查看了Bob发布的信息，他们分别是他的邻居Cheryl和住在新加坡的叔叔Jeffrey。如果Twitter使用strongly-consistent model，Cheryl和Jeffrey会看到Bob发布的关于猫的信息。
用这种方式来确保看到一致的信息不是最理想的，原因有以下几点:
首先，考虑地理位置的因素。Twitter选择一台数据库服务来实施strong consistency。该数据库服务位于Virginia，离Bob和Cheryl很近。这使得该服务的响应很快能到达Bob和Cheryl，但是到达Jeffrey所需的时间就变长了，因为猫的信息会跨越大西洋从Virginia到Singapore。从地理上来分析，Bob和Cheryl获取猫的信息所花的时间显然会比Jeffrey所需的时间短。这种只选择一台数据库服务来实施strong consistency model的结果是，一些用户，像Jeffrey，获取信息的时间会变得漫长起来。那么有什么方式能让这些用户获取信息的时间缩短?
抛弃只有一台数据服务的做法，Twitter可以选择2台数据库服务，每台数据库服务上的数据是相同的&amp;ndash;其中一台放到Virginia另外一台放到Singapore。此时，如果我们依然需要实施strong consistency model， 那么就意味着同一个用户从以上2台数据库服务在同一时间获取同一份信息，其得到的数据是一样的。这也意味着Twitter需要在数据库服务上实现复杂的同步算法&amp;ndash;在Bob发布的关于猫的信息提交到数据库之前，这些信息必须成功地提交到这2台数据服务上。此时，Bob的提交将往返于整个大西洋，最终导致用户的写操作变得更慢。
在Dynamo paper中，Amazon指出strong consistency在其业务场景中并不重要。具体应用到我们的例子中的场景是:Jeffrey与Cheryl在同一时间将看到不同的版本的关于猫的信息。数据库服务可以使用eventual consistency model来同步数据。也就是说最终不同用户会看到相同的信息。Jeffrey最终会看到Bob发布的关于猫的信息，而这条信息于2:32 PM传送到Singapore，即便是这条信息于2:30 PM传送到Virginia。
Strong consistency model对于某些场景相当重要-比如银行账户中的余额-但对于某些场景并不重要，比如Twitter示例或者Amazon的购物车系统。 去掉strong consistency model的使用而换成eventual consistency model大大促进了Dynamo的发展。对于Twitter示例或者Amazon的购物车系统这类业务场景，速度和可用性比同时获取相同数据更加重要。通过减弱关系型数据库的consistency model，Dynamo的工程师能够研发更加适合Amazon.</description>
    </item>
    
    <item>
      <title>DynamoDB的关键概念</title>
      <link>https://2cloudlab.com/nosql/key-concepts/</link>
      <pubDate>Mon, 11 Feb 2019 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/key-concepts/</guid>
      <description>在使用DynamoDB之前，我们需要了解一些基础概念，这些概念涉及了：表（tables），数据项（items）和每项数据的属性（attributes）、主键（primary keys），有简单主键（Partition Key）和复合主键（Partition Key + Sort Key）、附加索引（secondary indexes）、DynamoDB的读写能力。
本文将讨论关于DynamoDB的关键概念。完成这一章的学习之后，你将对以下概念有进一步的认识：
 表（tables），数据项（items）和每项数据的属性（attributes） 主键（primary keys），有简单主键（Partition Key）和复合主键（Partition Key + Sort Key） 附加索引（secondary indexes） DynamoDB的读写能力  表（tables），数据项（items）和每项数据的属性（attributes） 表（tables），数据项（items）和每项数据的属性（attributes）是DynamoDB的基础构建单元。
表是数据项的集合，不同类型的数据项都可以放到一张表里。例如：有一张Users表，该表存储了每一个用户的信息；有一张Orders表，该表存储了用户的所有订单信息。表的概念有点类似于关系型数据库中的表或MongoDB中的集合，与它们不同的是，DynamoDB中的表经常会存储不同类型的数据，比如用户信息以及该用户的所有订单信息会存储在同一张表中。
每条数据在表里就是一条记录（包含了多个属性（Attributes））。在表里，每条数据由主键（Primary Key）唯一确定。比如在Users表中，一条数据对应一个用户，这条数据包括了用户名，性别和住址等用户相关的信息。每条数据类似于关系型数据库表中的某一行或者MongoDB中的一个文档数据。
数据的属性组合成了每条数据，每条数据由多个数据属性构成。比如：一条用户数据包含了年龄属性，该属性存储了该用户的年龄。属性类似于关系型数据库表中的列或MongoDB中的属性。DynamoDB要求每一项数据都至少包含构成该数据主键的属性。
主键（Primary Key） 表中的每项数据由主键唯一标识。在创建表的时候，必须定义由哪些属性构成主键，当向表中新添数据的时候，该数据至少需要包含主键信息。
主键的类型有2类：简单主键和复合主键。前者仅由分区键（Partition Key）构成，而后者由分区键（Partiti Key）和排序键（Sort Key）组成。
简单主键类似于Memcached中的Key和SQL表中的主键。比如：用户名可以作为表Users的简单主键。
复合主键则更加复杂。你需要为表中的每一条数据提供分区键和排序键。排序键的作用在于使得同一分区的数据按照排序键的值进行排序。例如：某个用户的所有订单拥有相同的分区键（如：用户名），但每个订单的排序键（如：订单编号）是不相同的。
这里需要提醒的是：表中的每条数据是由主键唯一标识的。当使用复合主键来标识数据时，不同的数据可以拥有相同的分区键，此时，这些数据必须使用不同的排序键。由相同的分区键和不同的排序键构成的主键唯一标识了表中每一条数据。
复合主键可以支持复杂的数据查询模式。这些查询模式有：根据分区键来获取表中的数据；使用排序键来缩小查询范围。
读者可以根据拆解数据项来理解数据项的基本构成。
附加索引（Secondary Index） 主键唯一标识了表中的每一项数据，根据主键可以从表中获取到对应的数据项。然而有的时候，你需要根据其它模式来获取数据，比如你想查询订单金额超过某个范围的订单，而此时该表的Partition Key和Sort Key分别是用户名和订单号。使用该表的复合主键来满足这种查询显然是低效的，因此这个时候需要借助DynamoDB的附件索引来满足这一查询模式。附加索引有2种：local secondary index和global secondary index。
local secondary index使用了与表相同的分区键但是不同的排序键来构成索引。假设有一张Orders表，你想读取某个用户的所有订单，这些订单需要以订购数量（Amount）进行降序排序。此时，你只需要为Orders表创建一个local secondary index，该索引的分区键是用户ID（CustomerId），排序键是订单的订购数量（Amount）。开发者使用这个索引就能高效地获取某个用户的订单，并按照订单的数量进行排序。
global secondary index使用了与表完全不同的分区键和排序键来构成索引。你可以选择其它属性（不包含表的分区键）作为索引的分区键，从而构成该索引的简单主键，当然你也可以选择2个属性来构成索引的主键。假设有一张表，我们可以在这张表上定义一个global secondary index，该索引的分区键是订单号（OrderID），而排序键可以不设置，从而构成一个简单的主键。接着我们可以通过这个索引来根据订单号高效获取某个具体的订单，而无需通过查找用户和用户名下的订单这种低效的方式来查找。
附加索引是一个异常复杂的话题，但是这个功能却非常实用。它是实现不同查询模式的基础，想要深入了解和应用附件索引，读者可以前往这里。
读和写单元 当你使用MySQL，Postgres和MongoDB的时候，你需要启动一个服务器来运行这些数据库实例。你必须为这个服务器配置CPU，内存以及磁盘存储等。
而使用DynamoDB时，你不需要自己启动这些服务器，你只需要为创建的表指定读和写的单元，AWS就能自动地帮你启动服务器，并根据这些读写单元来启动服务器。这些读写单元限制了读写数据的吞吐量（KB/S），越多的读写单元其吞吐量会越大。与自己启动服务器来运行数据库实例的方式相比，这种方式的计费模式更加贴近真实的使用费用。
DynamoDB也能够自动增加和减少表的读写单元。这使得在数据使用的高峰期时，读写单元会自动增多，而在低峰期时，该读写单元会自动减少。通过这种根据实际使用情况来为表动态分配读写单元的方式能够减少支出。
下一步学习计划 如果你对DynamoDB的内部实现感兴趣，不妨去看看Dynamo Paper。如果不感兴趣，那么可以从搭建DynamoDB的环境开始，接着阅读对单条数据进行操作中的内容来理解数据的基本构成。
参考  原文链接  </description>
    </item>
    
    <item>
      <title>什么是DynamoDB？</title>
      <link>https://2cloudlab.com/nosql/what-is-dynamo-db/</link>
      <pubDate>Sun, 10 Feb 2019 12:27:38 +0600</pubDate>
      
      <guid>https://2cloudlab.com/nosql/what-is-dynamo-db/</guid>
      <description>DynamoDB是一个由AWS提供的NoSQL数据库服务。它完全托管于AWS，开发者只需要定义数据访问模式以及一些关键信息，就能通过HTTP API来使用它。它具有以下特点：
 随着数据量的剧增，它依然能够提供稳定的性能输出 它完全由AWS管理。开发人员不需要SSH到其服务器，不需要管理服务器，不需在服务器上更新OS补丁和加密库等 它提供了简单的API，这些API能够对数据进行增删改查，除此之外，开发者也能根据获取数据的场景来定义查询模式  DynamoDB适用于以下场景：
需存储大量数据同时要求低延迟的应用服务。随着应用服务的数据量增多，JOINs和高级的SQL操作会大大降低关系型数据库的性能，从而导致应用服务的性能变差。如果使用DynamoDB, 对任何数据量（即使超过100 TBs）的查询操作，其延时也能够确定在某个具体的范围。
AWS Serverless服务。AWS Lambda服务提供了能自动弹性伸缩，无状态且短暂的计算能力。开发者只需要定义事件就能触发并应用这些计算能力。DynamoDB对外提供了HTTP API，开发者可以通过HTTP API来操作DynamoDB。开发者可以使用IAM roles来为DynamoDB进行认证(你是谁)和授权(你拥有哪些权限，比如读或者读写某张表)。这些特性使得DynamoDB特别适用于Serverless服务。
对数据具有确定且简单的访问模式(比如根据国家来获取所有星巴克的门店)。如果你编写了一个推荐系统，并根据用户的偏好来推荐物品，那么把DynamoDB作为数据基础，能够为推荐系统提供更快且性能稳定的key-value访问模式。
准备好学习更多关于DynamoDB的知识？ 这个系列的文章将以一些关键的概念开始，学习tables，items以及关于DynamoDB的其它组成部分。如果你急于了解DynamoDB背后所应用的计算机科学理论，那么可以参考Dynamo Paper。
如果你只是想动手练练，那么可以从准备环境以及对单条数据进行操作开始。紧接着，你可以通过学习对多条数据进行操作来掌握DynamoDB的Queries和Scans功能。
以上只是一些基础知识，想要了解更多的高阶知识，可以参考secondary indexes和DynamoDB Streams。
如果想要获得更多关于DynamoDB的学习资料，那么这里将是一个不错的地方。
 原文链接  </description>
    </item>
    
    <item>
      <title>如何构建企业级VPC</title>
      <link>https://2cloudlab.com/portfolio/makeup-element/</link>
      <pubDate>Thu, 12 Jul 2018 16:57:54 +0600</pubDate>
      
      <guid>https://2cloudlab.com/portfolio/makeup-element/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo. nemo enim ipsam volup as tatem quia voluptassit aspernatur.aut odit aut fugit sed quia consequuntur magni dolores eo ratione voluptatem.sequi nesciunt neque porro quisquam est dolorem ipsum quia dolor amet consectetur adipisci velit. lorem ipsum dolor sit amet consectetur adipisicing elit sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.</description>
    </item>
    
    <item>
      <title>如何构建Kubernetes cluster</title>
      <link>https://2cloudlab.com/portfolio/how-to-build-kubernetes-cluster/</link>
      <pubDate>Thu, 12 Jul 2018 16:56:54 +0600</pubDate>
      
      <guid>https://2cloudlab.com/portfolio/how-to-build-kubernetes-cluster/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo. nemo enim ipsam volup as tatem quia voluptassit aspernatur.aut odit aut fugit sed quia consequuntur magni dolores eo ratione voluptatem.sequi nesciunt neque porro quisquam est dolorem ipsum quia dolor amet consectetur adipisci velit. lorem ipsum dolor sit amet consectetur adipisicing elit sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.</description>
    </item>
    
    <item>
      <title>设计数据应用的最佳实践</title>
      <link>https://2cloudlab.com/portfolio/how-to-craft-a-nosql-storage-system-in-one-day-dynamodb-large-scale-cloud-computing/</link>
      <pubDate>Thu, 12 Jul 2018 16:54:54 +0600</pubDate>
      
      <guid>https://2cloudlab.com/portfolio/how-to-craft-a-nosql-storage-system-in-one-day-dynamodb-large-scale-cloud-computing/</guid>
      <description>如何在一天之内搭建大规模存储系统-NoSQL 这篇指南将通过以下4步来帮助你在一天之内搭建大规模存储系统-NoSQL：
 开箱即用的云原生解决方案 现实情况 准备和实现 具体案例 存在的问题  开箱即用的云原生解决方案 module_dynamodb模块用于创建DynamoDB存储系统，它是NoSQL数据库，非常适合大规模数据存取，即便是数据量大规模增长了，它依然能提供10毫秒(ms)以内的数据存取性能。在使用它之前，你需要参考这里来准备研发环境和了解一些注意事项。这个解决方案能够帮助你创建一个NoSQL存取系统，你只需要提供表的主键或排序键以及创建索引即可。关于DynamoDB的使用，你可以参考这里，在那里，你可以看到如何使用DynamoDB来高效存取层级数据，除此之外，你还能看到Amazon是如何使用它来存取购物车信息的，实际上它需要一系列的教程来介绍它。这套开箱即用的解决方案能够帮助你快速地创建DynamoDB存储系统，它可以集成到其它服务，如下图最右边的部分所示：
 现实情况 你拥有一支非常擅长业务应用的研发团队，然而却缺乏大规模数据存取系统搭建的经验和软件工程经验。你迫切希望，你的团队能够研发一款面向互联网的服务，该服务能够大规模存取用户产生的数据。
准备和实现 首先，你需要为你的业务进行数据建模，以及分析数据存取模式。
数据建模要解决的问题是将现实世界里的对象抽象化，通过数据结构来定义和描述现实世界里的对象，每一个数据结构由一些字段来构成，每个字段有对应的类型，常见的类型有Number、String、Bool、Enum等等。
数据存取模式要解决的问题是搞清楚存取哪些数据和存取操作都有哪些。比如，你正在做一个电商服务，因此你需要存储商品数据，此外，你肯定会陈列商品以及展示商品的详细，这些都是属于数据存取模式要解决的问题。
你必须反复思考以上问题，把思考过程中的信息记录下来，因为，使用DynamoDB会存在一个问题：在已有的存取系统上增加新的数据存取模式会涉及到数据迁移，如果数据量很庞大，那么这种迁移工作会带来挑战，比如如何确保数据迁移的完整性、如何在不影响线上应用的情况下完成迁移等等。
其次，你需要创建main.tf文件，内容如下：
terraform { required_version = &amp;#34;= 0.12.19&amp;#34; } provider &amp;#34;aws&amp;#34; { version = &amp;#34;= 2.58&amp;#34; region = &amp;#34;ap-northeast-1&amp;#34; } module &amp;#34;dynamodb&amp;#34; { source = &amp;#34;github.com/2cloudlab/module_dynamodb//modules/dynamodb?ref=&amp;lt;tag&amp;gt;&amp;#34; name = &amp;lt;your-table-name&amp;gt; billing_mode = &amp;#34;PAY_PER_REQUEST&amp;#34; hash_key = &amp;lt;main-table-hash-key&amp;gt; range_key = &amp;lt;main-table-range-key&amp;gt; attributes = [ { name = &amp;lt;main-table-hash-key&amp;gt; type = &amp;#34;S&amp;#34; }, { name = &amp;lt;main-table-range-key&amp;gt; type = &amp;#34;S&amp;#34; }, ] } output &amp;#34;dynamodb_instance&amp;#34; { value = module.</description>
    </item>
    
    <item>
      <title>如何在一天之内上线一款WSGI兼容的Python Web App</title>
      <link>https://2cloudlab.com/portfolio/how-to-craft-a-wsgi-python-web-app-in-one-day-supervisor-ec2-gunicorn-nginx-cloud-computing/</link>
      <pubDate>Thu, 12 Jul 2018 16:53:54 +0600</pubDate>
      
      <guid>https://2cloudlab.com/portfolio/how-to-craft-a-wsgi-python-web-app-in-one-day-supervisor-ec2-gunicorn-nginx-cloud-computing/</guid>
      <description>如何在一天之内上线一款WSGI兼容的Python Web App 这篇指南将通过以下4步来帮助你在一天之内上线一款WSGI兼容的Python Web App：
 开箱即用的云原生解决方案 现实情况 准备和实现 具体案例 存在的问题  开箱即用的云原生解决方案 module_load_balancer模块用于创建WSGI兼容Web App所依赖的环境，非常适合只有Python技术栈的团队。在使用它之前，你需要参考这里来准备研发环境和了解一些注意事项。这个解决方案能够帮助你创建以下环境，你只需要提供图中Web App部分（它是基于Python来编写的并且是WSGI兼容的）。
 现实情况 你拥有一支非常擅长Python的研发团队，然而却缺乏DevOps和软件工程经验。你迫切希望，你的团队能够研发一款面向互联网的服务，并能快速接入互联网。
准备和实现 首先，你需要使用Python研发一个Web App，它是WSGI兼容的，然后将其打包成tar.gz格式，包中的目录结构如下所示：
. |-web-app-root | |-web-app | | |-wsgiapp.py | |-requirements.txt  web-app-root是包中的根目录，你可以重命名成其它 web-app是你的Web App所有可执行性文件所在的目录 wsgiapp.py是你的Web App的入口，里面定义了一个WSGI对象 requirements.txt是你的Web App所依赖的Python库  其次，你需要创建main.tf文件，内容如下：
terraform { required_version = &amp;#34;= 0.12.19&amp;#34; } provider &amp;#34;aws&amp;#34; { version = &amp;#34;= 2.58&amp;#34; region = &amp;#34;ap-northeast-1&amp;#34; } module &amp;#34;load_balance&amp;#34; { source = &amp;#34;github.com/2cloudlab/module_load_balancer//modules/load_balancer?ref=&amp;lt;tag&amp;gt;&amp;#34; download_url = &amp;lt;your-WSGI-Compatible-Python-Package-URL&amp;gt; package_base_dir = &amp;lt;your-root-folder-name-in-web-app-package&amp;gt; app_dir = &amp;lt;your-web-app-folder&amp;gt; envs = &amp;lt;your-app-environment-variables&amp;gt; wsgi_app = &amp;lt;WSGI-Entry&amp;gt; } output &amp;#34;alb_dns_name&amp;#34; { value = module.</description>
    </item>
    
  </channel>
</rss>